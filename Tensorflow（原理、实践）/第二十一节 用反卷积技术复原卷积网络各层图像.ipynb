{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 实例描述\n",
    "将cifar卷积代码中的每层卷积结果进行反卷积并输出，通过Tensorboard观察其结果。\n",
    "\n",
    "1. 替换Maxpool池化函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/Cellar/python/3.6.5/Frameworks/Python.framework/Versions/3.6/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weight_variable(shape):\n",
    "    initial = tf.truncated_normal(shape=shape,stddev=0.1)\n",
    "    return tf.Variable(initial)\n",
    "\n",
    "def bias_variable(shape):\n",
    "    initial = tf.constant(0.1,shape=shape)\n",
    "    return tf.Variable(initial)\n",
    "\n",
    "def conv2d(x,W):\n",
    "    return tf.nn.conv2d(x,W,strides=[1,1,1,1],padding='SAME')\n",
    "\n",
    "def max_pool_2x2(x):\n",
    "    return tf.nn.max_pool(x,ksize=[1,2,2,1],strides=[1,2,2,1],padding='SAME')\n",
    "\n",
    "def avg_pool6x6(x):\n",
    "    return tf.nn.avg_pool(x,ksize=[1,6,6,1],strides=[1,6,6,1],padding='SAME')\n",
    "\n",
    "def max_pool_with_argmax(net,stride):\n",
    "    _,mask = tf.nn.max_pool_with_argmax(net,ksize=[1,stride,stride,1],strides=[1,stride,stride,1],padding='SAME')\n",
    "    mask=tf.stop_gradient(mask)\n",
    "    net = tf.nn.max_pool(net,ksize=[1,stride,stride,1],strides=[1,stride,stride,1],padding='SAME')\n",
    "    return net,mask\n",
    "\n",
    "# 反最大池化\n",
    "def unpool(net,mask,stride):\n",
    "    \n",
    "    ksize = [1, stride, stride, 1]\n",
    "    input_shape = net.get_shape().as_list()\n",
    "    #  calculation new shape\n",
    "    output_shape = (input_shape[0], input_shape[1] * ksize[1], input_shape[2] * ksize[2], input_shape[3])\n",
    "    # calculation indices for batch, height, width and feature maps\n",
    "    one_like_mask = tf.ones_like(mask)\n",
    "    batch_range = tf.reshape(tf.range(output_shape[0], dtype=tf.int64), shape=[input_shape[0], 1, 1, 1])\n",
    "    b = one_like_mask * batch_range\n",
    "    y = mask // (output_shape[2] * output_shape[3])\n",
    "    x = mask % (output_shape[2] * output_shape[3]) // output_shape[3]\n",
    "    feature_range = tf.range(output_shape[3], dtype=tf.int64)\n",
    "    f = one_like_mask * feature_range\n",
    "    # transpose indices & reshape update values to one dimension\n",
    "    updates_size = tf.size(net)\n",
    "    indices = tf.transpose(tf.reshape(tf.stack([b, y, x, f]), [4, updates_size]))\n",
    "    values = tf.reshape(net, [updates_size])\n",
    "    ret = tf.scatter_nd(indices, values, output_shape)\n",
    "    return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "h_pool2_shape: (?, 6, 6, 64)\n"
     ]
    }
   ],
   "source": [
    "x = tf.placeholder(tf.float32,[None,24,24,3]) \n",
    "y = tf.placeholder(tf.float32,[None,10]) \n",
    "\n",
    "W_conv1 = weight_variable([5,5,3,64])\n",
    "b_conv1 = bias_variable([64])\n",
    "\n",
    "x_image = tf.reshape(x,[-1,24,24,3])\n",
    "\n",
    "h_conv1 = tf.nn.relu(conv2d(x_image,W_conv1)+b_conv1)\n",
    "h_pool1,mask1 = max_pool_with_argmax(h_conv1,2)\n",
    "\n",
    "W_conv2 = weight_variable([5,5,64,64])\n",
    "b_conv2 = bias_variable([64])\n",
    "\n",
    "h_conv2 = tf.nn.relu(conv2d(h_pool1,W_conv2)+b_conv2)\n",
    "h_pool2,mask = max_pool_with_argmax(h_conv2,2)\n",
    "print(\"h_pool2_shape:\",h_pool2.shape)\n",
    "\n",
    "# W_conv3 = weight_variable([5,5,64,10])\n",
    "# b_conv3 = bias_variable([10])\n",
    "# h_conv3 = tf.nn.relu(conv2d(h_pool2,W_conv3) + b_conv3)\n",
    "\n",
    "# nt_hpool3 = avg_pool6x6(h_conv3)\n",
    "# nt_hpool3_flat = tf.reshape(nt_hpool3,[-1,10])\n",
    "# y_conv = tf.nn.softmax(nt_hpool3_flat)\n",
    "\n",
    "# cross_entropy = -tf.reduce_sum(y*tf.log(y_conv))\n",
    "\n",
    "# train_step = tf.train.AdamOptimizer(1e-4).minimize(cross_entropy)\n",
    "\n",
    "# correct_prediction = tf.equal(tf.argmax(y_conv,1),tf.argmax(y,1))\n",
    "# accuracy = tf.reduce_mean(tf.cast(correct_prediction,\"float\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 上面最后一行是将h_pool2的形状打印出来，这也是在组建网络结构时常用的一种调试方法。**反卷积和反池化对形状都很敏感**(尤其层数太多时)。\n",
    "\n",
    "2.反卷积第二层卷积结果\n",
    "以第二池化输出的变量h_pool2为开始部分，沿着h_pool2生成的方式反向操作一层一层推导，直到生成原始图。![](imgs/21_deconvolution.png)\n",
    "上半部分是h_pool2卷积的过程，下半部分为反卷积过程。因为在卷积过程中，每个卷积后都要加上权重b，所以在反卷积过程中就要将b减去。由于Relu函数基本上是恒等变化（出了小于0的部分），所以在反向时不需要可逆操作，可直接略去。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_conv2 = unpool(h_pool2,mask,2) #(128,12,12,64)\n",
    "\n",
    "t_pool1 = tf.nn.conv2d_transpose(t_conv2 - b_conv2,W_conv2,h_pool1.shape,[1,1,1,1]) # (128,24,24,64)\n",
    "print(t_conv2.shape,h_pool1.shape,t_pool1.shape)\n",
    "t_conv1 = unpool(t_pool1,mask1,2)\n",
    "t_x_image = tf.nn.conv2d_transpose(t_conv1-b_conv1,W_conv1,x_image.shape,[1,1,1,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.反卷积第一层卷积结果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 第一层卷积还原\n",
    "t1_conv1 = unpool(h_pool1,mask1,2)\n",
    "t1_x_image = tf.nn.conv2d_transpose(t1_conv1-b_conv1,W_conv1,x_image.shape,[1,1,1,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4.合并还原结果，并输出给tensorboard输出"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 生成最终图像\n",
    "stitched_decodings = tf.concat((x_image,t1_x_image,t_x_image),axis=2)\n",
    "decoding_summary_op = tf.summary.image('source/cifar',stitched_decodings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5.session中写入log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_entropy = -tf.reduce_sum(y*tf.log(y_conv)) +(tf.nn.l2_loss(W_conv1)+tf.nn.l2_loss(W_conv2)+tf.nn.l2_loss(W_conv3))\n",
    "\n",
    "train_step = tf.train.AdamOptimizer(1e-4).minimize(cross_entropy)\n",
    "\n",
    "correct_prediction = tf.equal(tf.argmax(y_conv,1), tf.argmax(y,1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, \"float\"))\n",
    "\n",
    "\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "summary_writer = tf.summary.FileWriter('./log/', sess.graph)\n",
    "\n",
    "tf.train.start_queue_runners(sess=sess)\n",
    "\n",
    "for i in range(15000):#20000\n",
    "  image_batch, label_batch = sess.run([images_train, labels_train])\n",
    "  label_b = np.eye(10,dtype=float)[label_batch] #one hot\n",
    "  \n",
    "  train_step.run(feed_dict={x:image_batch, y: label_b},session=sess)\n",
    "  #_, decoding_summary = sess.run([train_step, decoding_summary_op],feed_dict={x:image_batch, y: label_b})\n",
    "  \n",
    "  if i%200 == 0:\n",
    "    train_accuracy = accuracy.eval(feed_dict={\n",
    "        x:image_batch, y: label_b},session=sess)\n",
    "    print( \"step %d, training accuracy %g\"%(i, train_accuracy))\n",
    "    print(\"cross_entropy\",cross_entropy.eval(feed_dict={x:image_batch, y: label_b},session=sess))\n",
    "    #summary_writer.add_summary(decoding_summary)\n",
    "\n",
    "\n",
    "image_batch, label_batch = sess.run([images_test, labels_test])\n",
    "label_b = np.eye(10,dtype=float)[label_batch]#one hot\n",
    "print (\"finished！ test accuracy %g\"%accuracy.eval(feed_dict={\n",
    "     x:image_batch, y: label_b},session=sess))\n",
    "decoding_summary = sess.run(decoding_summary_op,feed_dict={x:image_batch, y: label_b})\n",
    "summary_writer.add_summary(decoding_summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6.Tensorboard中查看![](imgs/21_deconvolution_image.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "第一幅是原始图片，不清晰的原因在于cifar10_input.inputs代码中，将图片做了归一化（变成-1~1之间的数）。第二幅是第一个卷积层还原的图片，第三幅是最后一个卷积层还原的图片。最后的卷积输出对图像的主要特征响应更强烈。\n",
    "\n",
    "为了让图片看的更清晰，可以先去掉归一化的操作。![](imgs/21_convolution_image.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "与归一化的效果对比，显然**归一化的图片卷积效果特征会更加明显**，这也是为什么要做归一化的原因。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
