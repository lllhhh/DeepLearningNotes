{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "编码步骤\n",
    "1. 导入MNIST数据集。\n",
    "2. 分析MNIST样本特点定义变量。\n",
    "3. 构建模型。\n",
    "4. 训练模型并输出中间状态参数。\n",
    "5. 测试模型。\n",
    "6. 保存模型。\n",
    "7. 读取模型。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 导入数据集\n",
    "利用TensorFlow代码下载MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\"MNIST_data/\",one_hot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 代码中的one_hot=True，表示将样本标签转化为one_hot编码。\n",
    "\n",
    "- MNIST数据集汇总图片是28x28像素，所以，每一幅就是1行784列的数据，括号中的每一个值代表一个像素。\n",
    "- 如果图片是黑白的，图片中黑色的地方数值为0，有图案的地方，数值为0~255之间的数字，代表其**颜色的深度**。\n",
    "- 如果是彩色的图片，一个像素会由3个值来表示RGB。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "输入数据： [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "输入数据的shape: (55000, 784)\n"
     ]
    }
   ],
   "source": [
    "print('输入数据：',mnist.train.images)\n",
    "print('输入数据的shape:',mnist.train.images.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    " # 显示第一张图片\n",
    "import pylab\n",
    "im = mnist.train.images[1]\n",
    "im = im.reshape(28,28)\n",
    "pylab.imshow(im)\n",
    "pylab.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "输入数据集的shape： (10000, 784)\n",
      "验证数据集的shape： (10000, 784)\n"
     ]
    }
   ],
   "source": [
    "# MNIST里面包含3个数据集：第一个是训练数据集，另外两个是测试数据集和验证数据集。\n",
    "print('输入数据集的shape：',mnist.test.images.shape)\n",
    "print('验证数据集的shape：',mnist.test.images.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 分析图片特点\n",
    "由于输入图片是550000x784的矩阵，所以先创建一个[None,784]的占位x和一个[None,10]的占位符y,然后使用feed机制将图片和标签输入进去。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets('MNIST_data/',one_hot=True)\n",
    "import pylab\n",
    "\n",
    "# 重置图\n",
    "tf.reset_default_graph()\n",
    "\n",
    "# 定义占位符\n",
    "x = tf.placeholder(tf.float32,[None,784]) # 数据集的维度是28x28=784\n",
    "y = tf.placeholder(tf.float32,[None,10]) # 数字0~9，共有10个类别"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 代码中的None,表示张量的第一个维度可以是任何长度的。x代表能够输入任何数量的MNIST图像，每一张图展平成784的向量。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 构建模型\n",
    "## 定义学习参数\n",
    "模型也需要权重值和偏执量，它们被统一叫做学习参数。在TensorFlow里，使用Variable来定义学习参数。\n",
    "\n",
    "一个Variable代表一个可修改的张量，定义在TensorFlow的图中，其本身也是一种变量。使用Variable定义的学习参数可以用于计算输入值，也可以在计算中被修改。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "W = tf.Variable(tf.random_normal([784,10]))\n",
    "b = tf.Variable(tf.zeros([10]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> W的维度是[784,10],因为想要用784维的图片向量乘以它，以得到一个10维的证据值向量，每一位对应不同数字类。b的形状是[10],所以可以直接把它加到输出上面。\n",
    "\n",
    "## 定义输出节点"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = tf.nn.softmax(tf.matmul(x,W)+b) #SoftMax分类 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "用tf.matmul(x,W)表示x乘以W，这里x是一个二维张量，拥有多个输入。然后再加上b,把他们的和输入到tf.nn.softmax函数里。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 定义反向传播的结构"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 损失函数\n",
    "cost = tf.reduce_mean(-tf.reduce_sum(y*tf.log(pred),reduction_indices=1))\n",
    "\n",
    "# 定义参数\n",
    "learning_rate = 0.01\n",
    "\n",
    "# 使用梯度下降优化器\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate).minimize(cost)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. 将生成的pred与样本标签y进行一次交叉熵的运算，然后取平均值。\n",
    "2. 将这个结果作为一次正向传播的误差，通过梯度下降的优化方法找到能够使这个误差最小化的b和W的偏移量。\n",
    "3. 更新b和W，使其调整为合适的参数。\n",
    "\n",
    "整个过程就是不断地让损失值变小。因为损失值越小，才能表明输出的结果跟标签数据越相近。当cost小到我们的需求时，这时的b和W就是训练出来的合适值。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 训练模型并输出中间状态参数\n",
    "> batch_size参数代表的意义很关键，在深度学习中，都是讲数据按批次地向里面放的。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0001 cost= 7.335221943\n",
      "Epoch: 0002 cost= 3.792151731\n",
      "Epoch: 0003 cost= 2.772239014\n",
      "Epoch: 0004 cost= 2.258920695\n",
      "Epoch: 0005 cost= 1.945905753\n",
      "Epoch: 0006 cost= 1.734733546\n",
      "Epoch: 0007 cost= 1.582136319\n",
      "Epoch: 0008 cost= 1.466087271\n",
      "Epoch: 0009 cost= 1.374811627\n",
      "Epoch: 0010 cost= 1.300416312\n",
      "Epoch: 0011 cost= 1.238649275\n",
      "Epoch: 0012 cost= 1.186055967\n",
      "Epoch: 0013 cost= 1.140930102\n",
      "Epoch: 0014 cost= 1.101536189\n",
      "Epoch: 0015 cost= 1.066803540\n",
      "Epoch: 0016 cost= 1.035886222\n",
      "Epoch: 0017 cost= 1.008233776\n",
      "Epoch: 0018 cost= 0.983150143\n",
      "Epoch: 0019 cost= 0.960485822\n",
      "Epoch: 0020 cost= 0.939669464\n",
      "Epoch: 0021 cost= 0.920529653\n",
      "Epoch: 0022 cost= 0.902779490\n",
      "Epoch: 0023 cost= 0.886409732\n",
      "Epoch: 0024 cost= 0.871160451\n",
      "Epoch: 0025 cost= 0.857006076\n",
      "finished!\n"
     ]
    }
   ],
   "source": [
    "training_epochs = 25\n",
    "batch_size = 100\n",
    "display_step = 1\n",
    "\n",
    "#启动session\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer()) # 初始化参数\n",
    "    \n",
    "    # 启动循环开始训练\n",
    "    for epoch in range(training_epochs):\n",
    "        avg_cost = 0.\n",
    "        total_batch = int(mnist.train.num_examples/batch_size)\n",
    "        # 循环所有数据集\n",
    "        \n",
    "        for i in range(total_batch):\n",
    "            batch_xs,batch_ys = mnist.train.next_batch(batch_size)\n",
    "            # 运行优化器\n",
    "            _,c = sess.run([optimizer,cost],feed_dict={x:batch_xs,y:batch_ys})\n",
    "            \n",
    "            # 计算平均loss值\n",
    "            avg_cost += c / total_batch\n",
    "            \n",
    "        if (epoch + 1) % display_step == 0:\n",
    "            print('Epoch:','%04d'% (epoch+1),'cost=','{:.9f}'.format(avg_cost))\n",
    "    print(\"finished!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "55000"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist.train.num_examples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 测试模型\n",
    "先将计算测试的网络结构建立起来，然后通过最终节点的eval将测试值运算出来。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Fetch argument <tf.Operation 'GradientDescent' type=NoOp> cannot be interpreted as a Tensor. (Operation name: \"GradientDescent\"\nop: \"NoOp\"\ninput: \"^GradientDescent/update_Variable/ApplyGradientDescent\"\ninput: \"^GradientDescent/update_Variable_1/ApplyGradientDescent\"\n is not an element of this graph.)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, fetches, contraction_fn)\u001b[0m\n\u001b[1;32m    281\u001b[0m         self._unique_fetches.append(ops.get_default_graph().as_graph_element(\n\u001b[0;32m--> 282\u001b[0;31m             fetch, allow_tensor=True, allow_operation=True))\n\u001b[0m\u001b[1;32m    283\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mas_graph_element\u001b[0;34m(self, obj, allow_tensor, allow_operation)\u001b[0m\n\u001b[1;32m   3338\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3339\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_as_graph_element_locked\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_operation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3340\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_as_graph_element_locked\u001b[0;34m(self, obj, allow_tensor, allow_operation)\u001b[0m\n\u001b[1;32m   3422\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3423\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Operation %s is not an element of this graph.\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3424\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Operation name: \"GradientDescent\"\nop: \"NoOp\"\ninput: \"^GradientDescent/update_Variable/ApplyGradientDescent\"\ninput: \"^GradientDescent/update_Variable_1/ApplyGradientDescent\"\n is not an element of this graph.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-53-a79b04ff7eb0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m             \u001b[0mbatch_xs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbatch_ys\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmnist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnext_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m             \u001b[0;31m# 运行优化器\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m             \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcost\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mbatch_xs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mbatch_ys\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m             \u001b[0;31m# 计算平均loss值\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    875\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    876\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 877\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    878\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    879\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1083\u001b[0m     \u001b[0;31m# Create a fetch handler to take care of the structure of fetches.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1084\u001b[0m     fetch_handler = _FetchHandler(\n\u001b[0;32m-> 1085\u001b[0;31m         self._graph, fetches, feed_dict_tensor, feed_handles=feed_handles)\n\u001b[0m\u001b[1;32m   1086\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1087\u001b[0m     \u001b[0;31m# Run request and get response.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, graph, fetches, feeds, feed_handles)\u001b[0m\n\u001b[1;32m    425\u001b[0m     \"\"\"\n\u001b[1;32m    426\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 427\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fetch_mapper\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_FetchMapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfor_fetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    428\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fetches\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    429\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_targets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mfor_fetch\u001b[0;34m(fetch)\u001b[0m\n\u001b[1;32m    243\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    244\u001b[0m       \u001b[0;31m# NOTE(touts): This is also the code path for namedtuples.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 245\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0m_ListFetchMapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    246\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    247\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0m_DictFetchMapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, fetches)\u001b[0m\n\u001b[1;32m    350\u001b[0m     \"\"\"\n\u001b[1;32m    351\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fetch_type\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 352\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_mappers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0m_FetchMapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfor_fetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfetch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    353\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_unique_fetches\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_value_indices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_uniquify_fetches\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_mappers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    354\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    350\u001b[0m     \"\"\"\n\u001b[1;32m    351\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fetch_type\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 352\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_mappers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0m_FetchMapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfor_fetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfetch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    353\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_unique_fetches\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_value_indices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_uniquify_fetches\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_mappers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    354\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mfor_fetch\u001b[0;34m(fetch)\u001b[0m\n\u001b[1;32m    251\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    252\u001b[0m           \u001b[0mfetches\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontraction_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfetch_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 253\u001b[0;31m           \u001b[0;32mreturn\u001b[0m \u001b[0m_ElementFetchMapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetches\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontraction_fn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    254\u001b[0m     \u001b[0;31m# Did not find anything.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    255\u001b[0m     raise TypeError('Fetch argument %r has invalid type %r' % (fetch,\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, fetches, contraction_fn)\u001b[0m\n\u001b[1;32m    287\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    288\u001b[0m         raise ValueError('Fetch argument %r cannot be interpreted as a '\n\u001b[0;32m--> 289\u001b[0;31m                          'Tensor. (%s)' % (fetch, str(e)))\n\u001b[0m\u001b[1;32m    290\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    291\u001b[0m         raise ValueError('Fetch argument %r cannot be interpreted as a '\n",
      "\u001b[0;31mValueError\u001b[0m: Fetch argument <tf.Operation 'GradientDescent' type=NoOp> cannot be interpreted as a Tensor. (Operation name: \"GradientDescent\"\nop: \"NoOp\"\ninput: \"^GradientDescent/update_Variable/ApplyGradientDescent\"\ninput: \"^GradientDescent/update_Variable_1/ApplyGradientDescent\"\n is not an element of this graph.)"
     ]
    }
   ],
   "source": [
    "training_epochs = 25\n",
    "batch_size = 100\n",
    "display_step = 1\n",
    "\n",
    "#启动session\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer()) # 初始化参数\n",
    "    \n",
    "    # 启动循环开始训练\n",
    "    for epoch in range(training_epochs):\n",
    "        avg_cost = 0.\n",
    "        total_batch = int(mnist.train.num_examples/batch_size)\n",
    "        # 循环所有数据集\n",
    "        \n",
    "        for i in range(total_batch):\n",
    "            batch_xs,batch_ys = mnist.train.next_batch(batch_size)\n",
    "            # 运行优化器\n",
    "            _,c = sess.run([optimizer,cost],feed_dict={x:batch_xs,y:batch_ys})\n",
    "            \n",
    "            # 计算平均loss值\n",
    "            avg_cost += c / total_batch\n",
    "            \n",
    "        if (epoch + 1) % display_step == 0:\n",
    "            print('Epoch:','%04d'% (epoch+1),'cost=','{:.9f}'.format(avg_cost))\n",
    "\n",
    "    \n",
    "    # 测试model\n",
    "    correct_prediction = tf.equal(tf.argmax(pred,1),tf.argmax(y,1))\n",
    "\n",
    "    # 计算准确率\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_prediction,tf.float32))\n",
    "\n",
    "    print('Accuracy:',accuracy.eval({x:mnist.test.images,y:mnist.test.labels}))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 并不是所有模型的测试错误率和训练时的最后一次损失值都很接近，这取决于训练样本和测试样本的分布情况，也取决于模型本身的拟合质量。\n",
    "# 保存模型\n",
    "\n",
    "首先要建立一个saver和一个路径，然后通过滴啊用save，自动将session中的参数保存起来。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0001 cost= 9.195762495\n",
      "Epoch: 0002 cost= 4.677690968\n",
      "Epoch: 0003 cost= 3.154947034\n",
      "Epoch: 0004 cost= 2.469959310\n",
      "Epoch: 0005 cost= 2.084750342\n",
      "Epoch: 0006 cost= 1.837843291\n",
      "Epoch: 0007 cost= 1.664582884\n",
      "Epoch: 0008 cost= 1.535432324\n",
      "Epoch: 0009 cost= 1.435061674\n",
      "Epoch: 0010 cost= 1.354502526\n",
      "Epoch: 0011 cost= 1.287571579\n",
      "Epoch: 0012 cost= 1.231363352\n",
      "Epoch: 0013 cost= 1.182989852\n",
      "Epoch: 0014 cost= 1.140837741\n",
      "Epoch: 0015 cost= 1.103623537\n",
      "Epoch: 0016 cost= 1.070715641\n",
      "Epoch: 0017 cost= 1.040945756\n",
      "Epoch: 0018 cost= 1.014077350\n",
      "Epoch: 0019 cost= 0.989651274\n",
      "Epoch: 0020 cost= 0.967348507\n",
      "Epoch: 0021 cost= 0.946714054\n",
      "Epoch: 0022 cost= 0.927750176\n",
      "Epoch: 0023 cost= 0.910034403\n",
      "Epoch: 0024 cost= 0.893677666\n",
      "Epoch: 0025 cost= 0.878218451\n",
      "Accuracy: 0.8365\n",
      "Model saved in file:log/521model.ckpt\n"
     ]
    }
   ],
   "source": [
    "training_epochs = 25\n",
    "batch_size = 100\n",
    "display_step = 1\n",
    "\n",
    "# 创建saver\n",
    "saver = tf.train.Saver()\n",
    "model_path = \"log/521model.ckpt\"\n",
    "\n",
    "#启动session\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer()) # 初始化参数\n",
    "    \n",
    "    # 启动循环开始训练\n",
    "    for epoch in range(training_epochs):\n",
    "        avg_cost = 0.\n",
    "        total_batch = int(mnist.train.num_examples/batch_size)\n",
    "        # 循环所有数据集\n",
    "        \n",
    "        for i in range(total_batch):\n",
    "            batch_xs,batch_ys = mnist.train.next_batch(batch_size)\n",
    "            # 运行优化器\n",
    "            _,c = sess.run([optimizer,cost],feed_dict={x:batch_xs,y:batch_ys})\n",
    "            \n",
    "            # 计算平均loss值\n",
    "            avg_cost += c / total_batch\n",
    "            \n",
    "        if (epoch + 1) % display_step == 0:\n",
    "            print('Epoch:','%04d'% (epoch+1),'cost=','{:.9f}'.format(avg_cost))\n",
    "\n",
    "    \n",
    "    # 测试model\n",
    "    correct_prediction = tf.equal(tf.argmax(pred,1),tf.argmax(y,1))\n",
    "\n",
    "    # 计算准确率\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_prediction,tf.float32))\n",
    "\n",
    "    print('Accuracy:',accuracy.eval({x:mnist.test.images,y:mnist.test.labels}))\n",
    "\n",
    "    \n",
    "    # 保存模型\n",
    "    save_path = saver.save(sess,model_path)\n",
    "    print(\"Model saved in file:%s\" % save_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 读取模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n",
      "Starting 2nd session...\n",
      "INFO:tensorflow:Restoring parameters from log/521model.ckpt\n",
      "Accuracy: 0.0836\n",
      "[3 9] [[1.4444648e-11 3.1308534e-08 1.2547371e-09 1.0000000e+00 9.6448110e-12\n",
      "  3.0280473e-11 8.3190228e-09 1.6260230e-08 2.2978067e-11 1.3381984e-12]\n",
      " [8.5979581e-02 1.0824383e-02 1.8037374e-08 4.3016538e-08 1.5118922e-09\n",
      "  5.0095891e-06 7.5961877e-09 5.7205878e-05 6.8581536e-11 9.0313375e-01]] [[1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvhp/UCwAADZxJREFUeJzt3X2MXOV1x/HfYVnb2ITIDsniLG4NZCEg1Jpk6hBh5UWE1yAZlOLEQo2RIpaqsRSURAqirco/UVATSJCIUpZi4VQUkpYQrMRJIVtU54U4rKlrA6axQxxhx/ZCTYsh4Jf16R9znSxm7zPD3Dtz7/p8P9JqZ+65L0ej/e29M8/MPObuAhDPcVU3AKAahB8IivADQRF+ICjCDwRF+IGgCD8QFOEHgiL8QFDH9/JgM2ymz9KcXh4SCOU1vaIDvt/aWbdQ+M3sUkm3S+qT9I/ufktq/Vmao/fZhUUOCSBhvY+2vW7Hl/1m1ifp65Iuk3SOpOVmdk6n+wPQW0We8y+WtM3dn3X3A5Lul7S0nLYAdFuR8A9Kem7S/R3Zstcxs2EzGzOzsYPaX+BwAMrU9Vf73X3E3Rvu3ujXzG4fDkCbioR/p6QFk+6fmi0DMA0UCf/jkobM7DQzmyHpE5LWlNMWgG7reKjP3Q+Z2UpJ/6bmUN8qd3+qtM4AdFWhcX53XytpbUm9AOgh3t4LBEX4gaAIPxAU4QeCIvxAUIQfCIrwA0ERfiAowg8ERfiBoAg/EBThB4Ii/EBQhB8IivADQRF+ICjCDwRF+IGgCD8QFOEHgiL8QFCEHwiK8ANBEX4gKMIPBEX4gaAIPxAU4QeCIvxAUIVm6TWz7ZL2SZqQdMjdG2U0hdc7/tTBZH3brW/Lrc2edSC57Wsb5iXrp925LVmf2DOerKO+CoU/82F3f6GE/QDoIS77gaCKht8lPWxmG8xsuIyGAPRG0cv+Je6+08zeIekRM3vG3ddNXiH7pzAsSbM0u+DhAJSl0Jnf3Xdmv8clPShp8RTrjLh7w90b/ZpZ5HAAStRx+M1sjpm95chtSRdLerKsxgB0V5HL/gFJD5rZkf38s7v/sJSuAHRdx+F392cl/WmJvUxfzX+AuV647vxk/aqVjybrHzjx+8n6BTMP59b6LH1xN9HI31aShk6/Ll2/lnH+6YqhPiAowg8ERfiBoAg/EBThB4Ii/EBQZXyqL7zn/ub9yfrmv7yjR5280YSnh/JaWTz062T9xeP60js4PFHo+OgezvxAUIQfCIrwA0ERfiAowg8ERfiBoAg/EBTj/G365V1/llvbfNltLbaeUW4zPXTvwh8l6x/tS39c2Rnnry3O/EBQhB8IivADQRF+ICjCDwRF+IGgCD8QFOP8bbrzw/fk1k6wYuP4Lx1+LVm/ZNOKZP3g99+eW/vSZ+9ObnvRCa8m61f/6pJk3Sf2JuuoL878QFCEHwiK8ANBEX4gKMIPBEX4gaAIPxBUy3F+M1sl6QpJ4+5+brZsnqRvSVooabukZe7+YvfarN7Fsw/m1iY8ve3fji9K1jcue1eyPnfr1mT91aVzc2utxvFbeWZ8IFlfcPj5QvtHddo5898j6dKjlt0oadTdhySNZvcBTCMtw+/u6yQd/TaupZJWZ7dXS7qy5L4AdFmnz/kH3H1Xdnu3pPS1IYDaKfyCn7u7pNxnvWY2bGZjZjZ2UPuLHg5ASToN/x4zmy9J2e/xvBXdfcTdG+7e6NfMDg8HoGydhn+NpCMfNVsh6aFy2gHQKy3Db2b3SXpM0llmtsPMPiXpFkkXmdlWSR/J7gOYRlqO87v78pzShSX3UmuXbLkit7b23WuS2/7griXJ+ju2/ixZ7zsr/T6AO2//Wm7tu6+cktz28+uWJetnfT39PoEWb3FAjfEOPyAowg8ERfiBoAg/EBThB4Ii/EBQfHV3m353x2BubdHQyuS27/yH9cl639z8j+RK0ifXjCbrZ/bPyq29qz/9Ses7/iVZlv/nU+kVMG1x5geCIvxAUIQfCIrwA0ERfiAowg8ERfiBoBjnb9PsB/PH6me32vi4vmR5y1fOSNavPjE9zp9y5sPDyfpZoxuTdT6ye+zizA8ERfiBoAg/EBThB4Ii/EBQhB8IivADQTHO3wO/u7KRrP/6sjuT9VZTgH9w85/n1s7+4tFzrB6170OH0jvHMYszPxAU4QeCIvxAUIQfCIrwA0ERfiAowg8E1XKc38xWSbpC0ri7n5stu1nSdZKez1a7yd3XdqvJY92EHy60/YH7B/L3ve2xQvvGsaudM/89ki6dYvlX3X1R9kPwgWmmZfjdfZ2k9NvEAEw7RZ7zrzSzTWa2yszS800BqJ1Ow/8NSWdIWiRpl6Rb81Y0s2EzGzOzsYPa3+HhAJSto/C7+x53n3D3w5LukrQ4se6IuzfcvdGvmZ32CaBkHYXfzOZPunuVpCfLaQdAr7Qz1HefpA9JOtnMdkj6O0kfMrNFan6z83ZJ13exRwBd0DL87r58isV3d6EXdGjiY/+TW9v36vk97ARHnPTAWLLuNfgeBd7hBwRF+IGgCD8QFOEHgiL8QFCEHwiKr+7uAbd0vc+K/Q/e8N5v5xffW2jXtdbqo9Cpx7XItu344RfT72b9q59ek1sbWvFEoWO3izM/EBThB4Ii/EBQhB8IivADQRF+ICjCDwTFOH8PvPXnzyXrN+xKT+F96ym/KLOdMIp8JXrRr1O/6IRXk/Uvv/9fc2sjOr3QsdvFmR8IivADQRF+ICjCDwRF+IGgCD8QFOEHgmKcvwcO7fxtsr71o/lTbEvSNQ98JFm/aTB/kuQ/mTErue10VufP87fy+f/4eG7tTD3e1WMfwZkfCIrwA0ERfiAowg8ERfiBoAg/EBThB4JqOc5vZgskfVPSgCSXNOLut5vZPEnfkrRQ0nZJy9z9xe61euw6tHtPsv7iBentv3Dutbm1l4fe2kFHf7Dj8hafaz8+XR/8Xv6f2Cuf/L/ktq88PTdZH/hF+ti7r96fW5vYm/5e/cF/T5b1v2f0JesnbZ9I1s9+dFtuLb1ledo58x+S9Dl3P0fS+ZI+bWbnSLpR0qi7D0kaze4DmCZaht/dd7n7E9ntfZK2SBqUtFTS6my11ZKu7FaTAMr3pp7zm9lCSedJWi9pwN13ZaXdaj4tADBNtB1+MztR0gOSbnD3lybX3N3VfD1gqu2GzWzMzMYOKv85GIDeaiv8ZtavZvDvdffvZIv3mNn8rD5f0vhU27r7iLs33L3Rr/SLLAB6p2X4zcwk3S1pi7vfNqm0RtKK7PYKSQ+V3x6AbrHmFXtiBbMlkn4sabOkI2MrN6n5vP/bkv5I0m/UHOrbm9rXSTbP32cXFu0ZQI71PqqXfG+LSeGbWo7zu/tPJOXtjCQD0xTv8AOCIvxAUIQfCIrwA0ERfiAowg8ERfiBoAg/EBThB4Ii/EBQhB8IivADQRF+ICjCDwRF+IGgCD8QFOEHgiL8QFCEHwiK8ANBEX4gKMIPBEX4gaAIPxAU4QeCIvxAUIQfCIrwA0ERfiAowg8E1TL8ZrbAzB41s6fN7Ckz+0y2/GYz22lmG7Ofy7vfLoCyHN/GOockfc7dnzCzt0jaYGaPZLWvuvtXutcegG5pGX533yVpV3Z7n5ltkTTY7cYAdNebes5vZgslnSdpfbZopZltMrNVZjY3Z5thMxszs7GD2l+oWQDlaTv8ZnaipAck3eDuL0n6hqQzJC1S88rg1qm2c/cRd2+4e6NfM0toGUAZ2gq/mfWrGfx73f07kuTue9x9wt0PS7pL0uLutQmgbO282m+S7pa0xd1vm7R8/qTVrpL0ZPntAeiWdl7tv0DSX0jabGYbs2U3SVpuZoskuaTtkq7vSocAuqKdV/t/IsmmKK0tvx0AvcI7/ICgCD8QFOEHgiL8QFCEHwiK8ANBEX4gKMIPBEX4gaAIPxAU4QeCIvxAUIQfCIrwA0GZu/fuYGbPS/rNpEUnS3qhZw28OXXtra59SfTWqTJ7+2N3f3s7K/Y0/G84uNmYuzcqayChrr3VtS+J3jpVVW9c9gNBEX4gqKrDP1Lx8VPq2ltd+5LorVOV9Fbpc34A1an6zA+gIpWE38wuNbP/NrNtZnZjFT3kMbPtZrY5m3l4rOJeVpnZuJk9OWnZPDN7xMy2Zr+nnCatot5qMXNzYmbpSh+7us143fPLfjPrk/RLSRdJ2iHpcUnL3f3pnjaSw8y2S2q4e+Vjwmb2AUkvS/qmu5+bLft7SXvd/ZbsH+dcd/9CTXq7WdLLVc/cnE0oM3/yzNKSrpR0rSp87BJ9LVMFj1sVZ/7Fkra5+7PufkDS/ZKWVtBH7bn7Okl7j1q8VNLq7PZqNf94ei6nt1pw913u/kR2e5+kIzNLV/rYJfqqRBXhH5T03KT7O1SvKb9d0sNmtsHMhqtuZgoD2bTpkrRb0kCVzUyh5czNvXTUzNK1eew6mfG6bLzg90ZL3P09ki6T9Ons8raWvPmcrU7DNW3N3NwrU8ws/XtVPnadznhdtirCv1PSgkn3T82W1YK778x+j0t6UPWbfXjPkUlSs9/jFffze3WauXmqmaVVg8euTjNeVxH+xyUNmdlpZjZD0ickramgjzcwsznZCzEyszmSLlb9Zh9eI2lFdnuFpIcq7OV16jJzc97M0qr4savdjNfu3vMfSZer+Yr/ryT9dRU95PR1uqT/yn6eqro3SfepeRl4UM3XRj4l6W2SRiVtlfQjSfNq1Ns/SdosaZOaQZtfUW9L1Lyk3yRpY/ZzedWPXaKvSh433uEHBMULfkBQhB8IivADQRF+ICjCDwRF+IGgCD8QFOEHgvp/WUg1TxEg0OYAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "import tensorflow as tf #导入tensorflow库\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot=True)\n",
    "import pylab \n",
    "\n",
    "# tf Graph Input\n",
    "x = tf.placeholder(tf.float32, [None, 784]) # mnist data维度 28*28=784\n",
    "y = tf.placeholder(tf.float32, [None, 10]) # 0-9 数字=> 10 classes\n",
    "\n",
    "# Set model weights\n",
    "W = tf.Variable(tf.random_normal([784, 10]))\n",
    "b = tf.Variable(tf.zeros([10]))\n",
    "\n",
    "# 构建模型\n",
    "pred = tf.nn.softmax(tf.matmul(x, W) + b) # Softmax分类\n",
    "\n",
    "# Minimize error using cross entropy\n",
    "cost = tf.reduce_mean(-tf.reduce_sum(y*tf.log(pred), reduction_indices=1))\n",
    "\n",
    "#读取模型\n",
    "print(\"Starting 2nd session...\")\n",
    "with tf.Session() as sess:\n",
    "    # Initialize variables\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    # Restore model weights from previously saved model\n",
    "    saver.restore(sess, model_path)\n",
    "    \n",
    "     # 测试 model\n",
    "    correct_prediction = tf.equal(tf.argmax(pred, 1), tf.argmax(y, 1))\n",
    "    # 计算准确率\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "    print (\"Accuracy:\", accuracy.eval({x: mnist.test.images, y: mnist.test.labels}))\n",
    "    \n",
    "    output = tf.argmax(pred, 1)\n",
    "    batch_xs, batch_ys = mnist.train.next_batch(2)\n",
    "    outputval,predv = sess.run([output,pred], feed_dict={x: batch_xs})\n",
    "    print(outputval,predv,batch_ys)\n",
    "\n",
    "    im = batch_xs[0]\n",
    "    im = im.reshape(-1,28)\n",
    "    pylab.imshow(im)\n",
    "    pylab.show()\n",
    "    \n",
    "    im = batch_xs[1]\n",
    "    im = im.reshape(-1,28)\n",
    "    pylab.imshow(im)\n",
    "    pylab.show()\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
