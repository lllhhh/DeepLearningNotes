{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 准备数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100,)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_X = np.linspace(-1, 1, 100)\n",
    "train_X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_Y = 2 * train_X + np.random.randn(train_X.shape[0]) * 0.3  # y=2x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(train_X,train_Y,'ro',label='Origin data')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 搭建模型\n",
    "### 正向模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 重置图\n",
    "tf.reset_default_graph()\n",
    "\n",
    "# 占位符\n",
    "X = tf.placeholder(\"float\")\n",
    "Y = tf.placeholder(\"float\")\n",
    "\n",
    "# 模型参数\n",
    "W = tf.Variable(tf.random_normal([1]), name=\"weights\")\n",
    "b = tf.Variable(tf.zeros([1]),name=\"bias\")\n",
    "\n",
    "# 向前结构\n",
    "z = tf.multiply(X,W) + b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 反向搭建模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 损失函数\n",
    "cost = tf.reduce_mean(tf.square(Y - z))\n",
    "\n",
    "#学习率\n",
    "learning_rate = 0.01 \n",
    "\n",
    "# 梯度下降 优化目标是最小化损失函数。 所以是minimize函数，并且把损失函数作为参数传递过去。\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate).minimize(cost) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 训练模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Fetch argument <tf.Operation 'GradientDescent' type=NoOp> cannot be interpreted as a Tensor. (Operation name: \"GradientDescent\"\nop: \"NoOp\"\ninput: \"^GradientDescent/update_weights/ApplyGradientDescent\"\ninput: \"^GradientDescent/update_bias/ApplyGradientDescent\"\n is not an element of this graph.)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m-----------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, fetches, contraction_fn)\u001b[0m\n\u001b[1;32m    281\u001b[0m         self._unique_fetches.append(ops.get_default_graph().as_graph_element(\n\u001b[0;32m--> 282\u001b[0;31m             fetch, allow_tensor=True, allow_operation=True))\n\u001b[0m\u001b[1;32m    283\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mas_graph_element\u001b[0;34m(self, obj, allow_tensor, allow_operation)\u001b[0m\n\u001b[1;32m   3612\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3613\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_as_graph_element_locked\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_operation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3614\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_as_graph_element_locked\u001b[0;34m(self, obj, allow_tensor, allow_operation)\u001b[0m\n\u001b[1;32m   3696\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3697\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Operation %s is not an element of this graph.\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3698\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Operation name: \"GradientDescent\"\nop: \"NoOp\"\ninput: \"^GradientDescent/update_weights/ApplyGradientDescent\"\ninput: \"^GradientDescent/update_bias/ApplyGradientDescent\"\n is not an element of this graph.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mValueError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-29-a28a4b25c36a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_X\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrain_Y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m             \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mY\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m             \u001b[0;31m# 显示训练的详细信息\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    898\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    899\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 900\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    901\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    902\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1118\u001b[0m     \u001b[0;31m# Create a fetch handler to take care of the structure of fetches.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1119\u001b[0m     fetch_handler = _FetchHandler(\n\u001b[0;32m-> 1120\u001b[0;31m         self._graph, fetches, feed_dict_tensor, feed_handles=feed_handles)\n\u001b[0m\u001b[1;32m   1121\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1122\u001b[0m     \u001b[0;31m# Run request and get response.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, graph, fetches, feeds, feed_handles)\u001b[0m\n\u001b[1;32m    425\u001b[0m     \"\"\"\n\u001b[1;32m    426\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 427\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fetch_mapper\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_FetchMapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfor_fetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    428\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fetches\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    429\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_targets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mfor_fetch\u001b[0;34m(fetch)\u001b[0m\n\u001b[1;32m    251\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    252\u001b[0m           \u001b[0mfetches\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontraction_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfetch_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 253\u001b[0;31m           \u001b[0;32mreturn\u001b[0m \u001b[0m_ElementFetchMapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetches\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontraction_fn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    254\u001b[0m     \u001b[0;31m# Did not find anything.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    255\u001b[0m     raise TypeError('Fetch argument %r has invalid type %r' % (fetch,\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, fetches, contraction_fn)\u001b[0m\n\u001b[1;32m    287\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    288\u001b[0m         raise ValueError('Fetch argument %r cannot be interpreted as a '\n\u001b[0;32m--> 289\u001b[0;31m                          'Tensor. (%s)' % (fetch, str(e)))\n\u001b[0m\u001b[1;32m    290\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    291\u001b[0m         raise ValueError('Fetch argument %r cannot be interpreted as a '\n",
      "\u001b[0;31mValueError\u001b[0m: Fetch argument <tf.Operation 'GradientDescent' type=NoOp> cannot be interpreted as a Tensor. (Operation name: \"GradientDescent\"\nop: \"NoOp\"\ninput: \"^GradientDescent/update_weights/ApplyGradientDescent\"\ninput: \"^GradientDescent/update_bias/ApplyGradientDescent\"\n is not an element of this graph.)"
     ]
    }
   ],
   "source": [
    "# 初始化所有变量\n",
    "init = tf.global_variables_initializer()\n",
    "plotdata = {'batchsize':[],'loss':[]} # 存放\n",
    "\n",
    "def moving_avarage(a, w=10):\n",
    "    if len(a) < w:\n",
    "        return a[:]\n",
    "    return [val if idx < w else sum(a[(idx-w):idx]/w) for idx,val in enumerate(a)]\n",
    "\n",
    "# 生成saver\n",
    "saver = tf.train.Saver()\n",
    "savedir = \"log/\"\n",
    "\n",
    "#定义参数\n",
    "training_epochs = 20\n",
    "display_step = 2\n",
    "\n",
    "# 启动\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    \n",
    "    # 想模型输入数据\n",
    "    for epoch in range(training_epochs):\n",
    "        for (x,y) in zip(train_X,train_Y):\n",
    "            sess.run(optimizer,feed_dict={X:x,Y:y})\n",
    "            \n",
    "            # 显示训练的详细信息\n",
    "        if epoch % display_step == 0:\n",
    "            loss = sess.run(cost,feed_dict={X:train_X,Y:train_Y})\n",
    "            print(\"Epoch:\",epoch+1,\"cost=\",loss,\"W=\",sess.run(W),\"b=\",sess.run(b))\n",
    "                \n",
    "            if not(loss == \"NA\"):\n",
    "                plotdata[\"batchsize\"].append(epoch)\n",
    "                plotdata[\"loss\"].append(loss)\n",
    "    \n",
    "    # 可视化\n",
    "    plotSesson(sess)\n",
    "    \n",
    "    print(\"Finished!\")\n",
    "    print(\"cost=\", sess.run(cost,feed_dict={X:train_X,Y:train_Y}),\"W=\",sess.run(W),\"b=\",sess.run(b))\n",
    "    \n",
    "    #保存模型\n",
    "    saver.save(sess,saverdir+'linermodel.cpkt')\n",
    "    \n",
    "    # 使用模型\n",
    "    print('x=0.2,z=',sess.run(z,feed_dict={X:0.2}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 训练模型可视化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 图形显示\n",
    "def plotSesson(sess):\n",
    "    plt.plot(train_X,train_Y,'ro',label='Original data')\n",
    "    plt.plot(train_X,sess.run(W) * train_X + sess.run(b),label=\"FittedLine\")\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    \n",
    "    plotdata['avgloss'] = moving_avarage(plotdata['loss'])\n",
    "    plt.figure()\n",
    "    plt.subplot(211)\n",
    "    plt.plot(plotdata['batchsize'],plotdata[\"avgloss\"],'b--')\n",
    "    plt.xlabel('Minibatch number')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.title('Minibatch number vs. Training Loss')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 了解TensorFlow开发的基本步骤\n",
    "> 1. 定义TensorFlow输入节点。\n",
    "2. 定义“学习参数”的变量。\n",
    "3. 定义“运算”。\n",
    "4. 优化函数，优化目标。\n",
    "5. 初始化所有变量。\n",
    "6. 迭代所有参数到最优解。\n",
    "7. 测试模型。\n",
    "8. 使用模型。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.定义输入节点的方法\n",
    "1. 通过占位符定义：一般使用这种方式。\n",
    "2. 通过字典类型定义：一般用于输入比较多的情况。\n",
    "3. 直接定义：一般很少使用。\n",
    "\n",
    "\n",
    "- 通过占位符定义\n",
    "使用tf.placeholder函数:\n",
    "___\n",
    "```Python\n",
    "X = tf.placeholder(\"float\")\n",
    "Y = tf.placeholder(\"float\")\n",
    "```\n",
    "___\n",
    "\n",
    "- 通过字典类型定义输入节点\n",
    "___\n",
    "```Python\n",
    "#占位符\n",
    "inputdict={\n",
    "    'x':tf.placeholder(\"float\")\n",
    "    'y':tf.placeholder(\"float\")\n",
    "}\n",
    "```\n",
    "___\n",
    "\n",
    "- 直接定义输入节点\n",
    "___\n",
    "```Python\n",
    "#生成模拟数据\n",
    "train_X =np.float32( np.linspace(-1, 1, 100))\n",
    "train_Y = 2 * train_X + np.random.randn(*train_X.shape) * 0.3 # y=2x，但是加入了噪声\n",
    "#图形显示\n",
    "plt.plot(train_X, train_Y, 'ro', label='Original data')\n",
    "plt.legend()\n",
    "plt.show()\n",
    " \n",
    "# 模型参数\n",
    "W = tf.Variable(tf.random_normal([1]), name=\"weight\")\n",
    "b = tf.Variable(tf.zeros([1]), name=\"bias\")\n",
    "# 前向结构\n",
    "z = tf.multiply(W, train_X)+ b\n",
    "```\n",
    "___\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. 定义“模型参数”的变量\n",
    "- 直接定义\n",
    "___\n",
    "```Python\n",
    "#模型参数\n",
    "W = tf.Variable(tf.random_normal([1]),name=\"weights\")\n",
    "b = tf.Variable(tf.zeros([1]),name=\"bias\")\n",
    "```\n",
    "___\n",
    "- 字典定义\n",
    "___\n",
    "```Python\n",
    "#模型参数\n",
    "paradict= {\n",
    "    'w':tf.Variable(tf.random_normal([1])),\n",
    "    'b':tf.Variable(tf.zeros([1]))\n",
    "}\n",
    "#\n",
    "z = tf.mutiply(X,paradict['w']) + paradict['b'] \n",
    "```\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. 定义“运算”\n",
    "- 定义正向传播模型\n",
    "> 例如多层神经网络、卷积神经网络、循环神经网络及更深层次的GoogleNet、Resnet等，它们都是由神经元以不同的组合方式组成的网络结构。\n",
    "- 定义损失函数\n",
    "> 损失函数主要是计算“输出值”与“目标值”之间的误差，是配合反向传播使用的。为了在反向传播中可以找到最小值，要求该函数必须是“可导”的。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. 优化函数，优化目标\n",
    "> 在有了正向结构和损失函数后，就是通过优化函数来优化学习参数了，这个过程也是在反向传播中完成的。\n",
    "> 反向传播过程，就是沿着正向传播的结构向相反方向将误差传递过去。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. 初始化所有变量\n",
    "___\n",
    "```Python\n",
    "init = tf.global_variables_initializer()\n",
    "#启动Session\n",
    "with tf.Session() as sess:\n",
    "    sess.tun(init)\n",
    "```\n",
    "___\n",
    "> 使用tf.global_variables_initializer()函数初始化所有变量的步骤，必须在所有变量和OP定义完成之后。这样才能保证定义的内容有效，否则，初始化之后定义的变量和OP都无法使用Session中的run来进行算值。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. 迭代更新参数到最优解\n",
    "在session中通过run来运算模型中的节点，在训练环节也是如此，只不过run里面放的是优化操作的OP，同时会在外层加上循环次数。\n",
    "___\n",
    "```Python\n",
    "for epoch in range(training_epochs):\n",
    "     for (x, y) in zip(train_X, train_Y):\n",
    "         sess.run(optimizer, feed_dict={X: x, Y: y})\n",
    "```\n",
    "___\n",
    "> 真正使用过程中会引入一个叫做MINIBATCH的概念进行迭代训练，即每次取一定量的数据同时放到网络中进行训练。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. 测试模型"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. 使用模型\n",
    "> 使用模型也与测试模型类似，只不过是将损失值的节点换成输出的节点即可。一般会把生成的模型保存起来，再通过载入已有的模型来进行实际的使用。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
