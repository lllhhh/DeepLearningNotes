{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "Python 3.8.3 64-bit",
   "display_name": "Python 3.8.3 64-bit",
   "metadata": {
    "interpreter": {
     "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from keras.utils import np_utils\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from keras.models import model_from_json\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "x: [[5.1 3.5 1.4 0.2]\n [4.9 3.  1.4 0.2]\n [4.7 3.2 1.3 0.2]\n [4.6 3.1 1.5 0.2]\n [5.  3.6 1.4 0.2]\n [5.4 3.9 1.7 0.4]\n [4.6 3.4 1.4 0.3]\n [5.  3.4 1.5 0.2]\n [4.4 2.9 1.4 0.2]\n [4.9 3.1 1.5 0.1]\n [5.4 3.7 1.5 0.2]\n [4.8 3.4 1.6 0.2]\n [4.8 3.  1.4 0.1]\n [4.3 3.  1.1 0.1]\n [5.8 4.  1.2 0.2]\n [5.7 4.4 1.5 0.4]\n [5.4 3.9 1.3 0.4]\n [5.1 3.5 1.4 0.3]\n [5.7 3.8 1.7 0.3]\n [5.1 3.8 1.5 0.3]\n [5.4 3.4 1.7 0.2]\n [5.1 3.7 1.5 0.4]\n [4.6 3.6 1.  0.2]\n [5.1 3.3 1.7 0.5]\n [4.8 3.4 1.9 0.2]\n [5.  3.  1.6 0.2]\n [5.  3.4 1.6 0.4]\n [5.2 3.5 1.5 0.2]\n [5.2 3.4 1.4 0.2]\n [4.7 3.2 1.6 0.2]\n [4.8 3.1 1.6 0.2]\n [5.4 3.4 1.5 0.4]\n [5.2 4.1 1.5 0.1]\n [5.5 4.2 1.4 0.2]\n [4.9 3.1 1.5 0.2]\n [5.  3.2 1.2 0.2]\n [5.5 3.5 1.3 0.2]\n [4.9 3.6 1.4 0.1]\n [4.4 3.  1.3 0.2]\n [5.1 3.4 1.5 0.2]\n [5.  3.5 1.3 0.3]\n [4.5 2.3 1.3 0.3]\n [4.4 3.2 1.3 0.2]\n [5.  3.5 1.6 0.6]\n [5.1 3.8 1.9 0.4]\n [4.8 3.  1.4 0.3]\n [5.1 3.8 1.6 0.2]\n [4.6 3.2 1.4 0.2]\n [5.3 3.7 1.5 0.2]\n [5.  3.3 1.4 0.2]\n [7.  3.2 4.7 1.4]\n [6.4 3.2 4.5 1.5]\n [6.9 3.1 4.9 1.5]\n [5.5 2.3 4.  1.3]\n [6.5 2.8 4.6 1.5]\n [5.7 2.8 4.5 1.3]\n [6.3 3.3 4.7 1.6]\n [4.9 2.4 3.3 1. ]\n [6.6 2.9 4.6 1.3]\n [5.2 2.7 3.9 1.4]\n [5.  2.  3.5 1. ]\n [5.9 3.  4.2 1.5]\n [6.  2.2 4.  1. ]\n [6.1 2.9 4.7 1.4]\n [5.6 2.9 3.6 1.3]\n [6.7 3.1 4.4 1.4]\n [5.6 3.  4.5 1.5]\n [5.8 2.7 4.1 1. ]\n [6.2 2.2 4.5 1.5]\n [5.6 2.5 3.9 1.1]\n [5.9 3.2 4.8 1.8]\n [6.1 2.8 4.  1.3]\n [6.3 2.5 4.9 1.5]\n [6.1 2.8 4.7 1.2]\n [6.4 2.9 4.3 1.3]\n [6.6 3.  4.4 1.4]\n [6.8 2.8 4.8 1.4]\n [6.7 3.  5.  1.7]\n [6.  2.9 4.5 1.5]\n [5.7 2.6 3.5 1. ]\n [5.5 2.4 3.8 1.1]\n [5.5 2.4 3.7 1. ]\n [5.8 2.7 3.9 1.2]\n [6.  2.7 5.1 1.6]\n [5.4 3.  4.5 1.5]\n [6.  3.4 4.5 1.6]\n [6.7 3.1 4.7 1.5]\n [6.3 2.3 4.4 1.3]\n [5.6 3.  4.1 1.3]\n [5.5 2.5 4.  1.3]\n [5.5 2.6 4.4 1.2]\n [6.1 3.  4.6 1.4]\n [5.8 2.6 4.  1.2]\n [5.  2.3 3.3 1. ]\n [5.6 2.7 4.2 1.3]\n [5.7 3.  4.2 1.2]\n [5.7 2.9 4.2 1.3]\n [6.2 2.9 4.3 1.3]\n [5.1 2.5 3.  1.1]\n [5.7 2.8 4.1 1.3]\n [6.3 3.3 6.  2.5]\n [5.8 2.7 5.1 1.9]\n [7.1 3.  5.9 2.1]\n [6.3 2.9 5.6 1.8]\n [6.5 3.  5.8 2.2]\n [7.6 3.  6.6 2.1]\n [4.9 2.5 4.5 1.7]\n [7.3 2.9 6.3 1.8]\n [6.7 2.5 5.8 1.8]\n [7.2 3.6 6.1 2.5]\n [6.5 3.2 5.1 2. ]\n [6.4 2.7 5.3 1.9]\n [6.8 3.  5.5 2.1]\n [5.7 2.5 5.  2. ]\n [5.8 2.8 5.1 2.4]\n [6.4 3.2 5.3 2.3]\n [6.5 3.  5.5 1.8]\n [7.7 3.8 6.7 2.2]\n [7.7 2.6 6.9 2.3]\n [6.  2.2 5.  1.5]\n [6.9 3.2 5.7 2.3]\n [5.6 2.8 4.9 2. ]\n [7.7 2.8 6.7 2. ]\n [6.3 2.7 4.9 1.8]\n [6.7 3.3 5.7 2.1]\n [7.2 3.2 6.  1.8]\n [6.2 2.8 4.8 1.8]\n [6.1 3.  4.9 1.8]\n [6.4 2.8 5.6 2.1]\n [7.2 3.  5.8 1.6]\n [7.4 2.8 6.1 1.9]\n [7.9 3.8 6.4 2. ]\n [6.4 2.8 5.6 2.2]\n [6.3 2.8 5.1 1.5]\n [6.1 2.6 5.6 1.4]\n [7.7 3.  6.1 2.3]\n [6.3 3.4 5.6 2.4]\n [6.4 3.1 5.5 1.8]\n [6.  3.  4.8 1.8]\n [6.9 3.1 5.4 2.1]\n [6.7 3.1 5.6 2.4]\n [6.9 3.1 5.1 2.3]\n [5.8 2.7 5.1 1.9]\n [6.8 3.2 5.9 2.3]\n [6.7 3.3 5.7 2.5]\n [6.7 3.  5.2 2.3]\n [6.3 2.5 5.  1.9]\n [6.5 3.  5.2 2. ]\n [6.2 3.4 5.4 2.3]\n [5.9 3.  5.1 1.8]]\ny: ['setosa' 'setosa' 'setosa' 'setosa' 'setosa' 'setosa' 'setosa' 'setosa'\n 'setosa' 'setosa' 'setosa' 'setosa' 'setosa' 'setosa' 'setosa' 'setosa'\n 'setosa' 'setosa' 'setosa' 'setosa' 'setosa' 'setosa' 'setosa' 'setosa'\n 'setosa' 'setosa' 'setosa' 'setosa' 'setosa' 'setosa' 'setosa' 'setosa'\n 'setosa' 'setosa' 'setosa' 'setosa' 'setosa' 'setosa' 'setosa' 'setosa'\n 'setosa' 'setosa' 'setosa' 'setosa' 'setosa' 'setosa' 'setosa' 'setosa'\n 'setosa' 'setosa' 'versicolor' 'versicolor' 'versicolor' 'versicolor'\n 'versicolor' 'versicolor' 'versicolor' 'versicolor' 'versicolor'\n 'versicolor' 'versicolor' 'versicolor' 'versicolor' 'versicolor'\n 'versicolor' 'versicolor' 'versicolor' 'versicolor' 'versicolor'\n 'versicolor' 'versicolor' 'versicolor' 'versicolor' 'versicolor'\n 'versicolor' 'versicolor' 'versicolor' 'versicolor' 'versicolor'\n 'versicolor' 'versicolor' 'versicolor' 'versicolor' 'versicolor'\n 'versicolor' 'versicolor' 'versicolor' 'versicolor' 'versicolor'\n 'versicolor' 'versicolor' 'versicolor' 'versicolor' 'versicolor'\n 'versicolor' 'versicolor' 'versicolor' 'versicolor' 'versicolor'\n 'versicolor' 'virginica' 'virginica' 'virginica' 'virginica' 'virginica'\n 'virginica' 'virginica' 'virginica' 'virginica' 'virginica' 'virginica'\n 'virginica' 'virginica' 'virginica' 'virginica' 'virginica' 'virginica'\n 'virginica' 'virginica' 'virginica' 'virginica' 'virginica' 'virginica'\n 'virginica' 'virginica' 'virginica' 'virginica' 'virginica' 'virginica'\n 'virginica' 'virginica' 'virginica' 'virginica' 'virginica' 'virginica'\n 'virginica' 'virginica' 'virginica' 'virginica' 'virginica' 'virginica'\n 'virginica' 'virginica' 'virginica' 'virginica' 'virginica' 'virginica'\n 'virginica' 'virginica' 'virginica']\ny_encoded: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2\n 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n 2 2]\nY_onehot: [[1. 0. 0.]\n [1. 0. 0.]\n [1. 0. 0.]\n [1. 0. 0.]\n [1. 0. 0.]\n [1. 0. 0.]\n [1. 0. 0.]\n [1. 0. 0.]\n [1. 0. 0.]\n [1. 0. 0.]\n [1. 0. 0.]\n [1. 0. 0.]\n [1. 0. 0.]\n [1. 0. 0.]\n [1. 0. 0.]\n [1. 0. 0.]\n [1. 0. 0.]\n [1. 0. 0.]\n [1. 0. 0.]\n [1. 0. 0.]\n [1. 0. 0.]\n [1. 0. 0.]\n [1. 0. 0.]\n [1. 0. 0.]\n [1. 0. 0.]\n [1. 0. 0.]\n [1. 0. 0.]\n [1. 0. 0.]\n [1. 0. 0.]\n [1. 0. 0.]\n [1. 0. 0.]\n [1. 0. 0.]\n [1. 0. 0.]\n [1. 0. 0.]\n [1. 0. 0.]\n [1. 0. 0.]\n [1. 0. 0.]\n [1. 0. 0.]\n [1. 0. 0.]\n [1. 0. 0.]\n [1. 0. 0.]\n [1. 0. 0.]\n [1. 0. 0.]\n [1. 0. 0.]\n [1. 0. 0.]\n [1. 0. 0.]\n [1. 0. 0.]\n [1. 0. 0.]\n [1. 0. 0.]\n [1. 0. 0.]\n [0. 1. 0.]\n [0. 1. 0.]\n [0. 1. 0.]\n [0. 1. 0.]\n [0. 1. 0.]\n [0. 1. 0.]\n [0. 1. 0.]\n [0. 1. 0.]\n [0. 1. 0.]\n [0. 1. 0.]\n [0. 1. 0.]\n [0. 1. 0.]\n [0. 1. 0.]\n [0. 1. 0.]\n [0. 1. 0.]\n [0. 1. 0.]\n [0. 1. 0.]\n [0. 1. 0.]\n [0. 1. 0.]\n [0. 1. 0.]\n [0. 1. 0.]\n [0. 1. 0.]\n [0. 1. 0.]\n [0. 1. 0.]\n [0. 1. 0.]\n [0. 1. 0.]\n [0. 1. 0.]\n [0. 1. 0.]\n [0. 1. 0.]\n [0. 1. 0.]\n [0. 1. 0.]\n [0. 1. 0.]\n [0. 1. 0.]\n [0. 1. 0.]\n [0. 1. 0.]\n [0. 1. 0.]\n [0. 1. 0.]\n [0. 1. 0.]\n [0. 1. 0.]\n [0. 1. 0.]\n [0. 1. 0.]\n [0. 1. 0.]\n [0. 1. 0.]\n [0. 1. 0.]\n [0. 1. 0.]\n [0. 1. 0.]\n [0. 1. 0.]\n [0. 1. 0.]\n [0. 1. 0.]\n [0. 1. 0.]\n [0. 0. 1.]\n [0. 0. 1.]\n [0. 0. 1.]\n [0. 0. 1.]\n [0. 0. 1.]\n [0. 0. 1.]\n [0. 0. 1.]\n [0. 0. 1.]\n [0. 0. 1.]\n [0. 0. 1.]\n [0. 0. 1.]\n [0. 0. 1.]\n [0. 0. 1.]\n [0. 0. 1.]\n [0. 0. 1.]\n [0. 0. 1.]\n [0. 0. 1.]\n [0. 0. 1.]\n [0. 0. 1.]\n [0. 0. 1.]\n [0. 0. 1.]\n [0. 0. 1.]\n [0. 0. 1.]\n [0. 0. 1.]\n [0. 0. 1.]\n [0. 0. 1.]\n [0. 0. 1.]\n [0. 0. 1.]\n [0. 0. 1.]\n [0. 0. 1.]\n [0. 0. 1.]\n [0. 0. 1.]\n [0. 0. 1.]\n [0. 0. 1.]\n [0. 0. 1.]\n [0. 0. 1.]\n [0. 0. 1.]\n [0. 0. 1.]\n [0. 0. 1.]\n [0. 0. 1.]\n [0. 0. 1.]\n [0. 0. 1.]\n [0. 0. 1.]\n [0. 0. 1.]\n [0. 0. 1.]\n [0. 0. 1.]\n [0. 0. 1.]\n [0. 0. 1.]\n [0. 0. 1.]\n [0. 0. 1.]]\n"
     ]
    }
   ],
   "source": [
    "seed = 13\n",
    "np.random.seed(seed)\n",
    "\n",
    "df = pd.read_csv('iris.csv')\n",
    "X = df.values[:, 1:5].astype(float)\n",
    "Y = df.values[:, 5]\n",
    "\n",
    "print(\"x:\",X)\n",
    "print(\"y:\",Y)\n",
    "\n",
    "# 对类别标签encode\n",
    "encoder = LabelEncoder()\n",
    "Y_encoded = encoder.fit_transform(Y)\n",
    "print(\"y_encoded:\", Y_encoded)\n",
    "\n",
    "# onthot编码\n",
    "Y_onehot = np_utils.to_categorical(Y_encoded)\n",
    "print(\"Y_onehot:\",Y_onehot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a network\n",
    "def baseline_model():\n",
    "    model = Sequential()\n",
    "    model.add(Dense(7,input_dim=4, activation='tanh'))\n",
    "    model.add(Dense(3, activation='softmax'))\n",
    "    model.compile(loss='MSE', optimizer='sgd', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "step - loss: 0.0794 - accuracy: 0.9037\n",
      "Epoch 18/20\n",
      "135/135 [==============================] - 0s 618us/step - loss: 0.0789 - accuracy: 0.9407\n",
      "Epoch 19/20\n",
      "135/135 [==============================] - 0s 604us/step - loss: 0.0751 - accuracy: 0.9407\n",
      "Epoch 20/20\n",
      "135/135 [==============================] - 0s 628us/step - loss: 0.0720 - accuracy: 0.9333\n",
      "15/15 [==============================] - 0s 831us/step - loss: 0.0835 - accuracy: 1.0000\n",
      "Epoch 1/20\n",
      "135/135 [==============================] - 0s 588us/step - loss: 0.2397 - accuracy: 0.3333\n",
      "Epoch 2/20\n",
      "135/135 [==============================] - 0s 711us/step - loss: 0.2281 - accuracy: 0.2889\n",
      "Epoch 3/20\n",
      "135/135 [==============================] - 0s 695us/step - loss: 0.2247 - accuracy: 0.2963\n",
      "Epoch 4/20\n",
      "135/135 [==============================] - 0s 701us/step - loss: 0.2236 - accuracy: 0.2815\n",
      "Epoch 5/20\n",
      "135/135 [==============================] - 0s 632us/step - loss: 0.2226 - accuracy: 0.3037\n",
      "Epoch 6/20\n",
      "135/135 [==============================] - 0s 602us/step - loss: 0.2217 - accuracy: 0.3556\n",
      "Epoch 7/20\n",
      "135/135 [==============================] - 0s 742us/step - loss: 0.2198 - accuracy: 0.3926\n",
      "Epoch 8/20\n",
      "135/135 [==============================] - 0s 736us/step - loss: 0.2173 - accuracy: 0.4222\n",
      "Epoch 9/20\n",
      "135/135 [==============================] - 0s 937us/step - loss: 0.2137 - accuracy: 0.5259\n",
      "Epoch 10/20\n",
      "135/135 [==============================] - 0s 714us/step - loss: 0.2083 - accuracy: 0.5852\n",
      "Epoch 11/20\n",
      "135/135 [==============================] - 0s 710us/step - loss: 0.2018 - accuracy: 0.5556\n",
      "Epoch 12/20\n",
      "135/135 [==============================] - 0s 703us/step - loss: 0.1945 - accuracy: 0.6148\n",
      "Epoch 13/20\n",
      "135/135 [==============================] - 0s 735us/step - loss: 0.1864 - accuracy: 0.6074\n",
      "Epoch 14/20\n",
      "135/135 [==============================] - 0s 641us/step - loss: 0.1799 - accuracy: 0.6519\n",
      "Epoch 15/20\n",
      "135/135 [==============================] - 0s 677us/step - loss: 0.1723 - accuracy: 0.6519\n",
      "Epoch 16/20\n",
      "135/135 [==============================] - 0s 603us/step - loss: 0.1659 - accuracy: 0.6741\n",
      "Epoch 17/20\n",
      "135/135 [==============================] - 0s 594us/step - loss: 0.1595 - accuracy: 0.6741\n",
      "Epoch 18/20\n",
      "135/135 [==============================] - 0s 846us/step - loss: 0.1539 - accuracy: 0.6741\n",
      "Epoch 19/20\n",
      "135/135 [==============================] - 0s 683us/step - loss: 0.1485 - accuracy: 0.6593\n",
      "Epoch 20/20\n",
      "135/135 [==============================] - 0s 609us/step - loss: 0.1446 - accuracy: 0.6000\n",
      "15/15 [==============================] - 0s 712us/step - loss: 0.1459 - accuracy: 0.6000\n",
      "Epoch 1/20\n",
      "135/135 [==============================] - 0s 565us/step - loss: 0.2686 - accuracy: 0.3333\n",
      "Epoch 2/20\n",
      "135/135 [==============================] - 0s 608us/step - loss: 0.2369 - accuracy: 0.3259\n",
      "Epoch 3/20\n",
      "135/135 [==============================] - 0s 591us/step - loss: 0.2293 - accuracy: 0.2519\n",
      "Epoch 4/20\n",
      "135/135 [==============================] - 0s 626us/step - loss: 0.2268 - accuracy: 0.3037\n",
      "Epoch 5/20\n",
      "135/135 [==============================] - 0s 940us/step - loss: 0.2255 - accuracy: 0.3407\n",
      "Epoch 6/20\n",
      "135/135 [==============================] - 0s 696us/step - loss: 0.2253 - accuracy: 0.3259\n",
      "Epoch 7/20\n",
      "135/135 [==============================] - 0s 684us/step - loss: 0.2249 - accuracy: 0.3259\n",
      "Epoch 8/20\n",
      "135/135 [==============================] - 0s 645us/step - loss: 0.2246 - accuracy: 0.3185\n",
      "Epoch 9/20\n",
      "135/135 [==============================] - 0s 632us/step - loss: 0.2246 - accuracy: 0.2963\n",
      "Epoch 10/20\n",
      "135/135 [==============================] - 0s 651us/step - loss: 0.2243 - accuracy: 0.3259\n",
      "Epoch 11/20\n",
      "135/135 [==============================] - 0s 702us/step - loss: 0.2244 - accuracy: 0.3037\n",
      "Epoch 12/20\n",
      "135/135 [==============================] - 0s 725us/step - loss: 0.2243 - accuracy: 0.2593\n",
      "Epoch 13/20\n",
      "135/135 [==============================] - 0s 682us/step - loss: 0.2241 - accuracy: 0.2370\n",
      "Epoch 14/20\n",
      "135/135 [==============================] - 0s 845us/step - loss: 0.2242 - accuracy: 0.2741\n",
      "Epoch 15/20\n",
      "135/135 [==============================] - 0s 739us/step - loss: 0.2241 - accuracy: 0.3333\n",
      "Epoch 16/20\n",
      "135/135 [==============================] - 0s 774us/step - loss: 0.2241 - accuracy: 0.2741\n",
      "Epoch 17/20\n",
      "135/135 [==============================] - 0s 743us/step - loss: 0.2240 - accuracy: 0.3333\n",
      "Epoch 18/20\n",
      "135/135 [==============================] - 0s 740us/step - loss: 0.2240 - accuracy: 0.3333\n",
      "Epoch 19/20\n",
      "135/135 [==============================] - 0s 718us/step - loss: 0.2239 - accuracy: 0.3037\n",
      "Epoch 20/20\n",
      "135/135 [==============================] - 0s 656us/step - loss: 0.2239 - accuracy: 0.2741\n",
      "15/15 [==============================] - 0s 762us/step - loss: 0.2237 - accuracy: 0.2667\n",
      "Epoch 1/20\n",
      "135/135 [==============================] - 0s 576us/step - loss: 0.3982 - accuracy: 0.3259\n",
      "Epoch 2/20\n",
      "135/135 [==============================] - 0s 614us/step - loss: 0.2708 - accuracy: 0.3333\n",
      "Epoch 3/20\n",
      "135/135 [==============================] - 0s 605us/step - loss: 0.2166 - accuracy: 0.5333\n",
      "Epoch 4/20\n",
      "135/135 [==============================] - 0s 644us/step - loss: 0.2007 - accuracy: 0.6593\n",
      "Epoch 5/20\n",
      "135/135 [==============================] - 0s 624us/step - loss: 0.1878 - accuracy: 0.6593\n",
      "Epoch 6/20\n",
      "135/135 [==============================] - 0s 636us/step - loss: 0.1728 - accuracy: 0.6593\n",
      "Epoch 7/20\n",
      "135/135 [==============================] - 0s 688us/step - loss: 0.1561 - accuracy: 0.6593\n",
      "Epoch 8/20\n",
      "135/135 [==============================] - 0s 677us/step - loss: 0.1393 - accuracy: 0.6593\n",
      "Epoch 9/20\n",
      "135/135 [==============================] - 0s 692us/step - loss: 0.1255 - accuracy: 0.7111\n",
      "Epoch 10/20\n",
      "135/135 [==============================] - 0s 810us/step - loss: 0.1156 - accuracy: 0.8074\n",
      "Epoch 11/20\n",
      "135/135 [==============================] - 0s 786us/step - loss: 0.1084 - accuracy: 0.8667\n",
      "Epoch 12/20\n",
      "135/135 [==============================] - 0s 825us/step - loss: 0.1015 - accuracy: 0.8667\n",
      "Epoch 13/20\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.0953 - accuracy: 0.8815\n",
      "Epoch 14/20\n",
      "135/135 [==============================] - 0s 723us/step - loss: 0.0916 - accuracy: 0.8741\n",
      "Epoch 15/20\n",
      "135/135 [==============================] - 0s 836us/step - loss: 0.0852 - accuracy: 0.8963\n",
      "Epoch 16/20\n",
      "135/135 [==============================] - 0s 737us/step - loss: 0.0847 - accuracy: 0.9037\n",
      "Epoch 17/20\n",
      "135/135 [==============================] - 0s 743us/step - loss: 0.0803 - accuracy: 0.9037\n",
      "Epoch 18/20\n",
      "135/135 [==============================] - 0s 724us/step - loss: 0.0741 - accuracy: 0.9037\n",
      "Epoch 19/20\n",
      "135/135 [==============================] - 0s 775us/step - loss: 0.0747 - accuracy: 0.9185\n",
      "Epoch 20/20\n",
      "135/135 [==============================] - 0s 741us/step - loss: 0.0716 - accuracy: 0.9185\n",
      "15/15 [==============================] - 0s 682us/step - loss: 0.0587 - accuracy: 0.9333\n",
      "Epoch 1/20\n",
      "135/135 [==============================] - 0s 570us/step - loss: 0.2217 - accuracy: 0.6444\n",
      "Epoch 2/20\n",
      "135/135 [==============================] - 0s 615us/step - loss: 0.2055 - accuracy: 0.6667\n",
      "Epoch 3/20\n",
      "135/135 [==============================] - 0s 718us/step - loss: 0.1972 - accuracy: 0.6667\n",
      "Epoch 4/20\n",
      "135/135 [==============================] - 0s 727us/step - loss: 0.1884 - accuracy: 0.6667\n",
      "Epoch 5/20\n",
      "135/135 [==============================] - 0s 742us/step - loss: 0.1816 - accuracy: 0.6593\n",
      "Epoch 6/20\n",
      "135/135 [==============================] - 0s 708us/step - loss: 0.1748 - accuracy: 0.6667\n",
      "Epoch 7/20\n",
      "135/135 [==============================] - 0s 790us/step - loss: 0.1681 - accuracy: 0.6667\n",
      "Epoch 8/20\n",
      "135/135 [==============================] - 0s 859us/step - loss: 0.1620 - accuracy: 0.6667\n",
      "Epoch 9/20\n",
      "135/135 [==============================] - 0s 733us/step - loss: 0.1566 - accuracy: 0.6667\n",
      "Epoch 10/20\n",
      "135/135 [==============================] - 0s 741us/step - loss: 0.1510 - accuracy: 0.6667\n",
      "Epoch 11/20\n",
      "135/135 [==============================] - 0s 732us/step - loss: 0.1465 - accuracy: 0.6667\n",
      "Epoch 12/20\n",
      "135/135 [==============================] - 0s 721us/step - loss: 0.1410 - accuracy: 0.6667\n",
      "Epoch 13/20\n",
      "135/135 [==============================] - 0s 721us/step - loss: 0.1376 - accuracy: 0.6667\n",
      "Epoch 14/20\n",
      "135/135 [==============================] - 0s 642us/step - loss: 0.1329 - accuracy: 0.6667\n",
      "Epoch 15/20\n",
      "135/135 [==============================] - 0s 716us/step - loss: 0.1297 - accuracy: 0.6667\n",
      "Epoch 16/20\n",
      "135/135 [==============================] - 0s 668us/step - loss: 0.1251 - accuracy: 0.6667\n",
      "Epoch 17/20\n",
      "135/135 [==============================] - 0s 675us/step - loss: 0.1245 - accuracy: 0.7407\n",
      "Epoch 18/20\n",
      "135/135 [==============================] - 0s 680us/step - loss: 0.1212 - accuracy: 0.7704\n",
      "Epoch 19/20\n",
      "135/135 [==============================] - 0s 710us/step - loss: 0.1188 - accuracy: 0.7778\n",
      "Epoch 20/20\n",
      "135/135 [==============================] - 0s 717us/step - loss: 0.1166 - accuracy: 0.7333\n",
      "15/15 [==============================] - 0s 847us/step - loss: 0.1087 - accuracy: 0.8667\n",
      "Epoch 1/20\n",
      "135/135 [==============================] - 0s 679us/step - loss: 0.2470 - accuracy: 0.2963\n",
      "Epoch 2/20\n",
      "135/135 [==============================] - 0s 934us/step - loss: 0.2063 - accuracy: 0.6593\n",
      "Epoch 3/20\n",
      "135/135 [==============================] - 0s 725us/step - loss: 0.1857 - accuracy: 0.6667\n",
      "Epoch 4/20\n",
      "135/135 [==============================] - 0s 782us/step - loss: 0.1725 - accuracy: 0.6667\n",
      "Epoch 5/20\n",
      "135/135 [==============================] - 0s 785us/step - loss: 0.1628 - accuracy: 0.6667\n",
      "Epoch 6/20\n",
      "135/135 [==============================] - 0s 718us/step - loss: 0.1550 - accuracy: 0.6667\n",
      "Epoch 7/20\n",
      "135/135 [==============================] - 0s 796us/step - loss: 0.1483 - accuracy: 0.6667\n",
      "Epoch 8/20\n",
      "135/135 [==============================] - 0s 715us/step - loss: 0.1430 - accuracy: 0.6667\n",
      "Epoch 9/20\n",
      "135/135 [==============================] - 0s 702us/step - loss: 0.1384 - accuracy: 0.6667\n",
      "Epoch 10/20\n",
      "135/135 [==============================] - 0s 697us/step - loss: 0.1346 - accuracy: 0.6667\n",
      "Epoch 11/20\n",
      "135/135 [==============================] - 0s 711us/step - loss: 0.1317 - accuracy: 0.6741\n",
      "Epoch 12/20\n",
      "135/135 [==============================] - 0s 996us/step - loss: 0.1287 - accuracy: 0.7333\n",
      "Epoch 13/20\n",
      "135/135 [==============================] - 0s 737us/step - loss: 0.1262 - accuracy: 0.6815\n",
      "Epoch 14/20\n",
      "135/135 [==============================] - 0s 981us/step - loss: 0.1240 - accuracy: 0.7259\n",
      "Epoch 15/20\n",
      "135/135 [==============================] - 0s 677us/step - loss: 0.1216 - accuracy: 0.7407\n",
      "Epoch 16/20\n",
      "135/135 [==============================] - 0s 796us/step - loss: 0.1190 - accuracy: 0.7111\n",
      "Epoch 17/20\n",
      "135/135 [==============================] - 0s 742us/step - loss: 0.1159 - accuracy: 0.7704\n",
      "Epoch 18/20\n",
      "135/135 [==============================] - 0s 796us/step - loss: 0.1116 - accuracy: 0.8667\n",
      "Epoch 19/20\n",
      "135/135 [==============================] - 0s 807us/step - loss: 0.1089 - accuracy: 0.8296\n",
      "Epoch 20/20\n",
      "135/135 [==============================] - 0s 806us/step - loss: 0.1067 - accuracy: 0.8074\n",
      "15/15 [==============================] - 0s 889us/step - loss: 0.1135 - accuracy: 0.9333\n",
      "Epoch 1/20\n",
      "135/135 [==============================] - 0s 661us/step - loss: 0.3385 - accuracy: 0.2296\n",
      "Epoch 2/20\n",
      "135/135 [==============================] - 0s 709us/step - loss: 0.2730 - accuracy: 0.2296\n",
      "Epoch 3/20\n",
      "135/135 [==============================] - 0s 666us/step - loss: 0.2636 - accuracy: 0.3704\n",
      "Epoch 4/20\n",
      "135/135 [==============================] - 0s 807us/step - loss: 0.2551 - accuracy: 0.4889\n",
      "Epoch 5/20\n",
      "135/135 [==============================] - 0s 897us/step - loss: 0.2414 - accuracy: 0.6593\n",
      "Epoch 6/20\n",
      "135/135 [==============================] - 0s 848us/step - loss: 0.2239 - accuracy: 0.6667\n",
      "Epoch 7/20\n",
      "135/135 [==============================] - 0s 823us/step - loss: 0.2055 - accuracy: 0.6667\n",
      "Epoch 8/20\n",
      "135/135 [==============================] - 0s 801us/step - loss: 0.1904 - accuracy: 0.6667\n",
      "Epoch 9/20\n",
      "135/135 [==============================] - 0s 876us/step - loss: 0.1761 - accuracy: 0.6667\n",
      "Epoch 10/20\n",
      "135/135 [==============================] - 0s 725us/step - loss: 0.1599 - accuracy: 0.6667\n",
      "Epoch 11/20\n",
      "135/135 [==============================] - 0s 694us/step - loss: 0.1487 - accuracy: 0.6667\n",
      "Epoch 12/20\n",
      "135/135 [==============================] - 0s 661us/step - loss: 0.1393 - accuracy: 0.6667\n",
      "Epoch 13/20\n",
      "135/135 [==============================] - 0s 715us/step - loss: 0.1320 - accuracy: 0.6815\n",
      "Epoch 14/20\n",
      "135/135 [==============================] - 0s 781us/step - loss: 0.1258 - accuracy: 0.6815\n",
      "Epoch 15/20\n",
      "135/135 [==============================] - 0s 707us/step - loss: 0.1207 - accuracy: 0.7333\n",
      "Epoch 16/20\n",
      "135/135 [==============================] - 0s 698us/step - loss: 0.1156 - accuracy: 0.7926\n",
      "Epoch 17/20\n",
      "135/135 [==============================] - 0s 681us/step - loss: 0.1116 - accuracy: 0.8148\n",
      "Epoch 18/20\n",
      "135/135 [==============================] - 0s 841us/step - loss: 0.1074 - accuracy: 0.8593\n",
      "Epoch 19/20\n",
      "135/135 [==============================] - 0s 838us/step - loss: 0.1039 - accuracy: 0.8296\n",
      "Epoch 20/20\n",
      "135/135 [==============================] - 0s 746us/step - loss: 0.0991 - accuracy: 0.8889\n",
      "15/15 [==============================] - 0s 716us/step - loss: 0.0889 - accuracy: 1.0000\n",
      "Epoch 1/20\n",
      "  1/135 [..............................] - ETA: 0s - loss: 0.0717 - accuracy: 1.0000WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0007s vs `on_train_batch_end` time: 0.0031s). Check your callbacks.\n",
      "135/135 [==============================] - 0s 816us/step - loss: 0.2832 - accuracy: 0.3556\n",
      "Epoch 2/20\n",
      "135/135 [==============================] - 0s 844us/step - loss: 0.2718 - accuracy: 0.3407\n",
      "Epoch 3/20\n",
      "135/135 [==============================] - 0s 936us/step - loss: 0.2591 - accuracy: 0.4519\n",
      "Epoch 4/20\n",
      "135/135 [==============================] - 0s 715us/step - loss: 0.2562 - accuracy: 0.4444\n",
      "Epoch 5/20\n",
      "135/135 [==============================] - 0s 704us/step - loss: 0.2532 - accuracy: 0.4963\n",
      "Epoch 6/20\n",
      "135/135 [==============================] - 0s 737us/step - loss: 0.2512 - accuracy: 0.5111\n",
      "Epoch 7/20\n",
      "135/135 [==============================] - 0s 688us/step - loss: 0.2506 - accuracy: 0.5407\n",
      "Epoch 8/20\n",
      "135/135 [==============================] - 0s 697us/step - loss: 0.2485 - accuracy: 0.5556\n",
      "Epoch 9/20\n",
      "135/135 [==============================] - 0s 693us/step - loss: 0.2461 - accuracy: 0.5481\n",
      "Epoch 10/20\n",
      "135/135 [==============================] - 0s 668us/step - loss: 0.2456 - accuracy: 0.5556\n",
      "Epoch 11/20\n",
      "135/135 [==============================] - 0s 680us/step - loss: 0.2437 - accuracy: 0.5704\n",
      "Epoch 12/20\n",
      "135/135 [==============================] - 0s 736us/step - loss: 0.2411 - accuracy: 0.5556\n",
      "Epoch 13/20\n",
      "135/135 [==============================] - 0s 810us/step - loss: 0.2380 - accuracy: 0.5852\n",
      "Epoch 14/20\n",
      "135/135 [==============================] - 0s 819us/step - loss: 0.2375 - accuracy: 0.5704\n",
      "Epoch 15/20\n",
      "135/135 [==============================] - 0s 949us/step - loss: 0.2363 - accuracy: 0.6074\n",
      "Epoch 16/20\n",
      "135/135 [==============================] - 0s 854us/step - loss: 0.2335 - accuracy: 0.5778\n",
      "Epoch 17/20\n",
      "135/135 [==============================] - 0s 819us/step - loss: 0.2311 - accuracy: 0.5926\n",
      "Epoch 18/20\n",
      "135/135 [==============================] - 0s 740us/step - loss: 0.2278 - accuracy: 0.5852\n",
      "Epoch 19/20\n",
      "135/135 [==============================] - 0s 728us/step - loss: 0.2264 - accuracy: 0.6222\n",
      "Epoch 20/20\n",
      "135/135 [==============================] - 0s 772us/step - loss: 0.2241 - accuracy: 0.6074\n",
      "15/15 [==============================] - 0s 817us/step - loss: 0.2366 - accuracy: 0.6000\n",
      "Epoch 1/20\n",
      "135/135 [==============================] - 0s 679us/step - loss: 0.3481 - accuracy: 0.3333\n",
      "Epoch 2/20\n",
      "135/135 [==============================] - 0s 710us/step - loss: 0.2814 - accuracy: 0.3333\n",
      "Epoch 3/20\n",
      "135/135 [==============================] - 0s 737us/step - loss: 0.2693 - accuracy: 0.3926\n",
      "Epoch 4/20\n",
      "135/135 [==============================] - 0s 707us/step - loss: 0.2647 - accuracy: 0.4370\n",
      "Epoch 5/20\n",
      "135/135 [==============================] - 0s 701us/step - loss: 0.2568 - accuracy: 0.4889\n",
      "Epoch 6/20\n",
      "135/135 [==============================] - 0s 707us/step - loss: 0.2455 - accuracy: 0.5259\n",
      "Epoch 7/20\n",
      "135/135 [==============================] - 0s 687us/step - loss: 0.2312 - accuracy: 0.5037\n",
      "Epoch 8/20\n",
      "135/135 [==============================] - 0s 741us/step - loss: 0.2136 - accuracy: 0.5556\n",
      "Epoch 9/20\n",
      "135/135 [==============================] - 0s 693us/step - loss: 0.1902 - accuracy: 0.4889\n",
      "Epoch 10/20\n",
      "135/135 [==============================] - 0s 810us/step - loss: 0.1672 - accuracy: 0.6593\n",
      "Epoch 11/20\n",
      "135/135 [==============================] - 0s 890us/step - loss: 0.1501 - accuracy: 0.6963\n",
      "Epoch 12/20\n",
      "135/135 [==============================] - 0s 708us/step - loss: 0.1386 - accuracy: 0.7185\n",
      "Epoch 13/20\n",
      "135/135 [==============================] - 0s 708us/step - loss: 0.1307 - accuracy: 0.6889\n",
      "Epoch 14/20\n",
      "135/135 [==============================] - 0s 694us/step - loss: 0.1244 - accuracy: 0.7556\n",
      "Epoch 15/20\n",
      "135/135 [==============================] - 0s 733us/step - loss: 0.1186 - accuracy: 0.7926\n",
      "Epoch 16/20\n",
      "135/135 [==============================] - 0s 719us/step - loss: 0.1152 - accuracy: 0.7481\n",
      "Epoch 17/20\n",
      "135/135 [==============================] - 0s 725us/step - loss: 0.1113 - accuracy: 0.8222\n",
      "Epoch 18/20\n",
      "135/135 [==============================] - 0s 725us/step - loss: 0.1081 - accuracy: 0.8296\n",
      "Epoch 19/20\n",
      "135/135 [==============================] - 0s 701us/step - loss: 0.1052 - accuracy: 0.8741\n",
      "Epoch 20/20\n",
      "135/135 [==============================] - 0s 687us/step - loss: 0.1020 - accuracy: 0.8815\n",
      "15/15 [==============================] - 0s 690us/step - loss: 0.0968 - accuracy: 0.8000\n",
      "Epoch 1/20\n",
      "135/135 [==============================] - 0s 655us/step - loss: 0.2150 - accuracy: 0.5111\n",
      "Epoch 2/20\n",
      "135/135 [==============================] - 0s 700us/step - loss: 0.1726 - accuracy: 0.6444\n",
      "Epoch 3/20\n",
      "135/135 [==============================] - 0s 696us/step - loss: 0.1563 - accuracy: 0.6593\n",
      "Epoch 4/20\n",
      "135/135 [==============================] - 0s 741us/step - loss: 0.1419 - accuracy: 0.7185\n",
      "Epoch 5/20\n",
      "135/135 [==============================] - 0s 635us/step - loss: 0.1342 - accuracy: 0.7333\n",
      "Epoch 6/20\n",
      "135/135 [==============================] - 0s 885us/step - loss: 0.1269 - accuracy: 0.7704\n",
      "Epoch 7/20\n",
      "135/135 [==============================] - 0s 753us/step - loss: 0.1211 - accuracy: 0.7852\n",
      "Epoch 8/20\n",
      "135/135 [==============================] - 0s 723us/step - loss: 0.1172 - accuracy: 0.7630\n",
      "Epoch 9/20\n",
      "135/135 [==============================] - 0s 799us/step - loss: 0.1145 - accuracy: 0.7778\n",
      "Epoch 10/20\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.1108 - accuracy: 0.8074\n",
      "Epoch 11/20\n",
      "135/135 [==============================] - 0s 728us/step - loss: 0.1051 - accuracy: 0.8296\n",
      "Epoch 12/20\n",
      "135/135 [==============================] - 0s 698us/step - loss: 0.1039 - accuracy: 0.8370\n",
      "Epoch 13/20\n",
      "135/135 [==============================] - 0s 689us/step - loss: 0.1001 - accuracy: 0.8519\n",
      "Epoch 14/20\n",
      "135/135 [==============================] - 0s 718us/step - loss: 0.0979 - accuracy: 0.8593\n",
      "Epoch 15/20\n",
      "135/135 [==============================] - 0s 873us/step - loss: 0.0956 - accuracy: 0.8741\n",
      "Epoch 16/20\n",
      "135/135 [==============================] - 0s 730us/step - loss: 0.0935 - accuracy: 0.8963\n",
      "Epoch 17/20\n",
      "135/135 [==============================] - 0s 698us/step - loss: 0.0884 - accuracy: 0.8815\n",
      "Epoch 18/20\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.0881 - accuracy: 0.8667\n",
      "Epoch 19/20\n",
      "135/135 [==============================] - 0s 805us/step - loss: 0.0826 - accuracy: 0.8889\n",
      "Epoch 20/20\n",
      "135/135 [==============================] - 0s 723us/step - loss: 0.0824 - accuracy: 0.8889\n",
      "15/15 [==============================] - 0s 859us/step - loss: 0.0815 - accuracy: 0.9333\n",
      "Accuracy of cross validation, mean 0.79, std 0.22\n"
     ]
    }
   ],
   "source": [
    "# eatimator \n",
    "estimator = KerasClassifier(build_fn=baseline_model, epochs=20, batch_size=1, verbose=1)\n",
    "\n",
    "#evalute\n",
    "kfold = KFold(n_splits=10, shuffle=True, random_state=seed)\n",
    "result = cross_val_score(estimator, X, Y_onehot, cv=kfold)\n",
    "\n",
    "# print(result)\n",
    "print(\"Accuracy of cross validation, mean %.2f, std %.2f\" % (result.mean(), result.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/20\n",
      "150/150 [==============================] - 0s 746us/step - loss: 0.1430 - accuracy: 0.7533\n",
      "Epoch 2/20\n",
      "150/150 [==============================] - 0s 687us/step - loss: 0.1292 - accuracy: 0.7867\n",
      "Epoch 3/20\n",
      "150/150 [==============================] - 0s 709us/step - loss: 0.1207 - accuracy: 0.7733\n",
      "Epoch 4/20\n",
      "150/150 [==============================] - 0s 623us/step - loss: 0.1153 - accuracy: 0.7800\n",
      "Epoch 5/20\n",
      "150/150 [==============================] - 0s 587us/step - loss: 0.1084 - accuracy: 0.8200\n",
      "Epoch 6/20\n",
      "150/150 [==============================] - 0s 576us/step - loss: 0.1032 - accuracy: 0.8200\n",
      "Epoch 7/20\n",
      "150/150 [==============================] - 0s 626us/step - loss: 0.0975 - accuracy: 0.8533\n",
      "Epoch 8/20\n",
      "150/150 [==============================] - 0s 605us/step - loss: 0.0947 - accuracy: 0.8867\n",
      "Epoch 9/20\n",
      "150/150 [==============================] - 0s 735us/step - loss: 0.0893 - accuracy: 0.8733\n",
      "Epoch 10/20\n",
      "150/150 [==============================] - 0s 622us/step - loss: 0.0836 - accuracy: 0.9000\n",
      "Epoch 11/20\n",
      "150/150 [==============================] - 0s 652us/step - loss: 0.0820 - accuracy: 0.8867\n",
      "Epoch 12/20\n",
      "150/150 [==============================] - 0s 612us/step - loss: 0.0761 - accuracy: 0.9200\n",
      "Epoch 13/20\n",
      "150/150 [==============================] - 0s 586us/step - loss: 0.0742 - accuracy: 0.9067\n",
      "Epoch 14/20\n",
      "150/150 [==============================] - 0s 613us/step - loss: 0.0719 - accuracy: 0.9133\n",
      "Epoch 15/20\n",
      "150/150 [==============================] - 0s 603us/step - loss: 0.0692 - accuracy: 0.9000\n",
      "Epoch 16/20\n",
      "150/150 [==============================] - 0s 597us/step - loss: 0.0652 - accuracy: 0.9267\n",
      "Epoch 17/20\n",
      "150/150 [==============================] - 0s 625us/step - loss: 0.0625 - accuracy: 0.9200\n",
      "Epoch 18/20\n",
      "150/150 [==============================] - 0s 620us/step - loss: 0.0617 - accuracy: 0.9333\n",
      "Epoch 19/20\n",
      "150/150 [==============================] - 0s 684us/step - loss: 0.0581 - accuracy: 0.9400\n",
      "Epoch 20/20\n",
      "150/150 [==============================] - 0s 751us/step - loss: 0.0555 - accuracy: 0.9200\n",
      "saved model to disk\n"
     ]
    }
   ],
   "source": [
    "# save model\n",
    "estimator.fit(X, Y_onehot)\n",
    "model_json = estimator.model.to_json()\n",
    "with open('model.json','w') as json_file:\n",
    "    json_file.write(model_json)\n",
    "\n",
    "estimator.model.save_weights(\"model.h5\")\n",
    "print('saved model to disk')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "loaded model from disk\npredicted probability:[[0.9065162  0.07521492 0.01826887]\n [0.8845505  0.09373784 0.02171168]\n [0.898711   0.08174448 0.01954448]\n [0.8760452  0.09971994 0.0242349 ]\n [0.9084866  0.07339084 0.01812258]\n [0.90028906 0.07901687 0.02069412]\n [0.89548546 0.08328155 0.02123293]\n [0.89663744 0.08303855 0.02032407]\n [0.8697849  0.10523178 0.02498332]\n [0.88616914 0.09209443 0.02173639]\n [0.9093797  0.07274692 0.01787329]\n [0.8865292  0.09054709 0.02292374]\n [0.88784266 0.0909749  0.02118239]\n [0.9027048  0.07902649 0.01826876]\n [0.9246374  0.06097921 0.01438343]\n [0.92176527 0.06205084 0.01618393]\n [0.9184942  0.06522346 0.01628229]\n [0.9041775  0.07695249 0.0188701 ]\n [0.9027082  0.0778852  0.01940664]\n [0.9077982  0.07331918 0.01888268]\n [0.88744146 0.09076101 0.02179752]\n [0.90255016 0.07749657 0.01995334]\n [0.9218983  0.06335945 0.01474231]\n [0.8569154  0.1153876  0.02769695]\n [0.8536818  0.11591625 0.03040188]\n [0.8660459  0.10888862 0.02506548]\n [0.88030106 0.09584614 0.02385278]\n [0.9021812  0.07863317 0.01918567]\n [0.90431345 0.0772064  0.01848011]\n [0.873757   0.10123905 0.02500389]\n [0.8691715  0.10558435 0.02524413]\n [0.89385664 0.08561338 0.02052993]\n [0.9172247  0.06606749 0.01670778]\n [0.9221334  0.06245823 0.01540836]\n [0.88124055 0.09608675 0.02267275]\n [0.9067452  0.07562884 0.01762602]\n [0.9130537  0.07027955 0.01666675]\n [0.90954906 0.07260735 0.01784356]\n [0.8860402  0.09197129 0.02198852]\n [0.8977328  0.08228657 0.01998068]\n [0.9085832  0.07347621 0.01794058]\n [0.81611264 0.15240589 0.03148149]\n [0.89534146 0.0839787  0.02067982]\n [0.87563217 0.09892665 0.0254412 ]\n [0.8751847  0.09786351 0.02695176]\n [0.8777808  0.09911212 0.02310704]\n [0.90481454 0.07561922 0.01956628]\n [0.890419   0.08805532 0.02152571]\n [0.9086871  0.073212   0.01810077]\n [0.8991887  0.08133593 0.01947537]\n [0.0652275  0.6894172  0.24535535]\n [0.06173202 0.63419884 0.3040691 ]\n [0.06325001 0.5463769  0.3903732 ]\n [0.06619506 0.44812447 0.48568046]\n [0.0651784  0.5187964  0.41602525]\n [0.05408388 0.36738142 0.57853466]\n [0.05649869 0.52840054 0.4151008 ]\n [0.08464918 0.6573838  0.25796703]\n [0.06737404 0.586189   0.346437  ]\n [0.06210844 0.50782037 0.43007118]\n [0.07754403 0.51838523 0.4040708 ]\n [0.06256188 0.60697305 0.3304651 ]\n [0.07944911 0.58151543 0.33903545]\n [0.0552643  0.3877978  0.5569379 ]\n [0.07644396 0.73443574 0.18912028]\n [0.06640489 0.71902394 0.21457113]\n [0.05118309 0.37512165 0.5736952 ]\n [0.07180386 0.59540653 0.33278954]\n [0.06356476 0.35263073 0.5838044 ]\n [0.07298016 0.5892036  0.33781624]\n [0.04642481 0.33293796 0.62063724]\n [0.07080691 0.7021547  0.22703835]\n [0.05126828 0.2712272  0.67750454]\n [0.05698572 0.3796203  0.563394  ]\n [0.06868501 0.67137736 0.25993767]\n [0.06697413 0.6866285  0.24639729]\n [0.06690882 0.5040681  0.42902315]\n [0.056244   0.39548442 0.5482716 ]\n [0.05833342 0.45651364 0.48515302]\n [0.0875723  0.7458484  0.16657923]\n [0.07442311 0.58899224 0.3365846 ]\n [0.07865311 0.6378493  0.28349772]\n [0.07240196 0.6680481  0.25954992]\n [0.03887663 0.19597071 0.76515263]\n [0.04761583 0.3282213  0.62416285]\n [0.05607196 0.57367605 0.370252  ]\n [0.06344092 0.5948205  0.34173858]\n [0.07127394 0.4604958  0.4682302 ]\n [0.06378508 0.5908859  0.34532902]\n [0.06592025 0.4973321  0.43674767]\n [0.05324237 0.32916385 0.6175938 ]\n [0.05828529 0.46469653 0.47701824]\n [0.07128605 0.60843337 0.3202806 ]\n [0.08494374 0.66328734 0.25176898]\n [0.06166702 0.46930552 0.46902743]\n [0.06421664 0.57590705 0.3598763 ]\n [0.06304262 0.5465114  0.39044592]\n [0.06709954 0.6267483  0.3061521 ]\n [0.1035825  0.74330527 0.15311228]\n [0.06558944 0.5728747  0.36153582]\n [0.02769738 0.12990592 0.8423967 ]\n [0.0347796  0.17058924 0.7946311 ]\n [0.03643156 0.17369227 0.78987616]\n [0.032857   0.15634258 0.81080043]\n [0.03106883 0.14595877 0.8229724 ]\n [0.03192719 0.14073744 0.82733536]\n [0.03532452 0.17770526 0.7869702 ]\n [0.03365285 0.14967458 0.81667256]\n [0.03496195 0.15303521 0.81200284]\n [0.03356194 0.17708734 0.7893507 ]\n [0.04728993 0.32231987 0.63039017]\n [0.03923409 0.19220893 0.76855695]\n [0.04048688 0.21235254 0.7471606 ]\n [0.03476331 0.16497691 0.80025977]\n [0.03321866 0.16472772 0.8020536 ]\n [0.03854349 0.22173136 0.7397251 ]\n [0.03716752 0.18963909 0.7731934 ]\n [0.03096008 0.15290825 0.8161317 ]\n [0.03076436 0.1310342  0.83820146]\n [0.04190271 0.18923102 0.7688663 ]\n [0.03694596 0.19313739 0.7699167 ]\n [0.03591813 0.18804361 0.7760382 ]\n [0.03265767 0.14027497 0.8270673 ]\n [0.04926404 0.28233135 0.6684045 ]\n [0.03537472 0.1874726  0.7771527 ]\n [0.03711507 0.18460013 0.7782848 ]\n [0.05056854 0.31658703 0.6328445 ]\n [0.04605937 0.2931087  0.66083187]\n [0.03297994 0.15407084 0.8129492 ]\n [0.04272809 0.21408863 0.74318326]\n [0.03820606 0.1704972  0.7912967 ]\n [0.03925896 0.2252281  0.735513  ]\n [0.03269098 0.15250622 0.81480277]\n [0.04521508 0.24764404 0.70714086]\n [0.03216112 0.14483826 0.8230006 ]\n [0.04090099 0.19173323 0.7673658 ]\n [0.03221928 0.17004023 0.79774046]\n [0.03604947 0.18737778 0.77657276]\n [0.04715883 0.31209585 0.6407453 ]\n [0.04535523 0.2650319  0.68961287]\n [0.03564012 0.18168914 0.78267074]\n [0.05321832 0.37387118 0.57291055]\n [0.0347796  0.17058924 0.7946311 ]\n [0.03233754 0.15742122 0.8102413 ]\n [0.0339586  0.1768216  0.7892198 ]\n [0.04576311 0.27035725 0.6838797 ]\n [0.04518822 0.2264165  0.7283953 ]\n [0.04362745 0.25184038 0.70453215]\n [0.03489517 0.19828293 0.76682186]\n [0.03739214 0.2042637  0.75834423]]\npredicted label[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 2 1 2 1 1 1 1 1 1 1 2 1 1 2 1 2 1 2 1 2 2\n 1 1 1 2 2 1 1 1 1 2 2 1 1 2 1 1 2 2 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2\n 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n 2 2]\n"
     ]
    }
   ],
   "source": [
    "# load model\n",
    "json_file = open(\"model.json\",\"r\")\n",
    "loaded_model_json = json_file.read()\n",
    "json_file.close()\n",
    "\n",
    "loaded_model = model_from_json(loaded_model_json)\n",
    "loaded_model.load_weights(\"model.h5\")\n",
    "print(\"loaded model from disk\")\n",
    "\n",
    "predicted = loaded_model.predict(X)\n",
    "print(\"predicted probability:\"+str(predicted))\n",
    "\n",
    "predicted_label = loaded_model.predict_classes(X)\n",
    "print(\"predicted label\"+str(predicted_label))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}