{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "\n",
    "#导入数据\n",
    "iris = load_iris()\n",
    "\n",
    "#特征矩阵\n",
    "iris.data[:5]\n",
    "\n",
    "#目标向量\n",
    "iris.target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 归一化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.80377277, 0.55160877, 0.22064351, 0.0315205 ],\n",
       "       [0.82813287, 0.50702013, 0.23660939, 0.03380134],\n",
       "       [0.80533308, 0.54831188, 0.2227517 , 0.03426949],\n",
       "       [0.80003025, 0.53915082, 0.26087943, 0.03478392],\n",
       "       [0.790965  , 0.5694948 , 0.2214702 , 0.0316386 ]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import Normalizer\n",
    "\n",
    "#归一化，返回值为归一化后的数据\n",
    "Normalizer().fit_transform(iris.data[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 对定量特征二值化\n",
    "定量特征二值化的核心在于设定一个阈值，大于阈值的赋值为1，小于等于阈值的赋值为0，\n",
    "$$\n",
    "x'= \n",
    "\\begin{cases}\n",
    "1,x>threshold \\\\\n",
    "0,x<=threshold\n",
    "\\end{cases}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 1., 0., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [1., 1., 0., 0.],\n",
       "       [1., 1., 0., 0.],\n",
       "       [1., 1., 0., 0.]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import Binarizer\n",
    "\n",
    "#二值化\n",
    "Binarizer(threshold=3).fit_transform(iris.data[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 对定性特征哑编码\n",
    "由于iris数据集的特征皆为定量特征，故使用其目标值进行哑编码。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<150x3 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 150 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "#哑编码，对iris数据集目标值，返回值为哑编码后的数据\n",
    "OneHotEncoder(categories='auto').fit_transform(iris.target.reshape((-1,1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 缺失值计算\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5.84333333, 3.05733333, 3.758     , 1.19933333],\n",
       "       [5.1       , 3.5       , 1.4       , 0.2       ],\n",
       "       [4.9       , 3.        , 1.4       , 0.2       ],\n",
       "       [4.7       , 3.2       , 1.3       , 0.2       ],\n",
       "       [4.6       , 3.1       , 1.5       , 0.2       ],\n",
       "       [5.        , 3.6       , 1.4       , 0.2       ],\n",
       "       [5.4       , 3.9       , 1.7       , 0.4       ],\n",
       "       [4.6       , 3.4       , 1.4       , 0.3       ],\n",
       "       [5.        , 3.4       , 1.5       , 0.2       ],\n",
       "       [4.4       , 2.9       , 1.4       , 0.2       ],\n",
       "       [4.9       , 3.1       , 1.5       , 0.1       ],\n",
       "       [5.4       , 3.7       , 1.5       , 0.2       ],\n",
       "       [4.8       , 3.4       , 1.6       , 0.2       ],\n",
       "       [4.8       , 3.        , 1.4       , 0.1       ],\n",
       "       [4.3       , 3.        , 1.1       , 0.1       ],\n",
       "       [5.8       , 4.        , 1.2       , 0.2       ],\n",
       "       [5.7       , 4.4       , 1.5       , 0.4       ],\n",
       "       [5.4       , 3.9       , 1.3       , 0.4       ],\n",
       "       [5.1       , 3.5       , 1.4       , 0.3       ],\n",
       "       [5.7       , 3.8       , 1.7       , 0.3       ],\n",
       "       [5.1       , 3.8       , 1.5       , 0.3       ],\n",
       "       [5.4       , 3.4       , 1.7       , 0.2       ],\n",
       "       [5.1       , 3.7       , 1.5       , 0.4       ],\n",
       "       [4.6       , 3.6       , 1.        , 0.2       ],\n",
       "       [5.1       , 3.3       , 1.7       , 0.5       ],\n",
       "       [4.8       , 3.4       , 1.9       , 0.2       ],\n",
       "       [5.        , 3.        , 1.6       , 0.2       ],\n",
       "       [5.        , 3.4       , 1.6       , 0.4       ],\n",
       "       [5.2       , 3.5       , 1.5       , 0.2       ],\n",
       "       [5.2       , 3.4       , 1.4       , 0.2       ],\n",
       "       [4.7       , 3.2       , 1.6       , 0.2       ],\n",
       "       [4.8       , 3.1       , 1.6       , 0.2       ],\n",
       "       [5.4       , 3.4       , 1.5       , 0.4       ],\n",
       "       [5.2       , 4.1       , 1.5       , 0.1       ],\n",
       "       [5.5       , 4.2       , 1.4       , 0.2       ],\n",
       "       [4.9       , 3.1       , 1.5       , 0.2       ],\n",
       "       [5.        , 3.2       , 1.2       , 0.2       ],\n",
       "       [5.5       , 3.5       , 1.3       , 0.2       ],\n",
       "       [4.9       , 3.6       , 1.4       , 0.1       ],\n",
       "       [4.4       , 3.        , 1.3       , 0.2       ],\n",
       "       [5.1       , 3.4       , 1.5       , 0.2       ],\n",
       "       [5.        , 3.5       , 1.3       , 0.3       ],\n",
       "       [4.5       , 2.3       , 1.3       , 0.3       ],\n",
       "       [4.4       , 3.2       , 1.3       , 0.2       ],\n",
       "       [5.        , 3.5       , 1.6       , 0.6       ],\n",
       "       [5.1       , 3.8       , 1.9       , 0.4       ],\n",
       "       [4.8       , 3.        , 1.4       , 0.3       ],\n",
       "       [5.1       , 3.8       , 1.6       , 0.2       ],\n",
       "       [4.6       , 3.2       , 1.4       , 0.2       ],\n",
       "       [5.3       , 3.7       , 1.5       , 0.2       ],\n",
       "       [5.        , 3.3       , 1.4       , 0.2       ],\n",
       "       [7.        , 3.2       , 4.7       , 1.4       ],\n",
       "       [6.4       , 3.2       , 4.5       , 1.5       ],\n",
       "       [6.9       , 3.1       , 4.9       , 1.5       ],\n",
       "       [5.5       , 2.3       , 4.        , 1.3       ],\n",
       "       [6.5       , 2.8       , 4.6       , 1.5       ],\n",
       "       [5.7       , 2.8       , 4.5       , 1.3       ],\n",
       "       [6.3       , 3.3       , 4.7       , 1.6       ],\n",
       "       [4.9       , 2.4       , 3.3       , 1.        ],\n",
       "       [6.6       , 2.9       , 4.6       , 1.3       ],\n",
       "       [5.2       , 2.7       , 3.9       , 1.4       ],\n",
       "       [5.        , 2.        , 3.5       , 1.        ],\n",
       "       [5.9       , 3.        , 4.2       , 1.5       ],\n",
       "       [6.        , 2.2       , 4.        , 1.        ],\n",
       "       [6.1       , 2.9       , 4.7       , 1.4       ],\n",
       "       [5.6       , 2.9       , 3.6       , 1.3       ],\n",
       "       [6.7       , 3.1       , 4.4       , 1.4       ],\n",
       "       [5.6       , 3.        , 4.5       , 1.5       ],\n",
       "       [5.8       , 2.7       , 4.1       , 1.        ],\n",
       "       [6.2       , 2.2       , 4.5       , 1.5       ],\n",
       "       [5.6       , 2.5       , 3.9       , 1.1       ],\n",
       "       [5.9       , 3.2       , 4.8       , 1.8       ],\n",
       "       [6.1       , 2.8       , 4.        , 1.3       ],\n",
       "       [6.3       , 2.5       , 4.9       , 1.5       ],\n",
       "       [6.1       , 2.8       , 4.7       , 1.2       ],\n",
       "       [6.4       , 2.9       , 4.3       , 1.3       ],\n",
       "       [6.6       , 3.        , 4.4       , 1.4       ],\n",
       "       [6.8       , 2.8       , 4.8       , 1.4       ],\n",
       "       [6.7       , 3.        , 5.        , 1.7       ],\n",
       "       [6.        , 2.9       , 4.5       , 1.5       ],\n",
       "       [5.7       , 2.6       , 3.5       , 1.        ],\n",
       "       [5.5       , 2.4       , 3.8       , 1.1       ],\n",
       "       [5.5       , 2.4       , 3.7       , 1.        ],\n",
       "       [5.8       , 2.7       , 3.9       , 1.2       ],\n",
       "       [6.        , 2.7       , 5.1       , 1.6       ],\n",
       "       [5.4       , 3.        , 4.5       , 1.5       ],\n",
       "       [6.        , 3.4       , 4.5       , 1.6       ],\n",
       "       [6.7       , 3.1       , 4.7       , 1.5       ],\n",
       "       [6.3       , 2.3       , 4.4       , 1.3       ],\n",
       "       [5.6       , 3.        , 4.1       , 1.3       ],\n",
       "       [5.5       , 2.5       , 4.        , 1.3       ],\n",
       "       [5.5       , 2.6       , 4.4       , 1.2       ],\n",
       "       [6.1       , 3.        , 4.6       , 1.4       ],\n",
       "       [5.8       , 2.6       , 4.        , 1.2       ],\n",
       "       [5.        , 2.3       , 3.3       , 1.        ],\n",
       "       [5.6       , 2.7       , 4.2       , 1.3       ],\n",
       "       [5.7       , 3.        , 4.2       , 1.2       ],\n",
       "       [5.7       , 2.9       , 4.2       , 1.3       ],\n",
       "       [6.2       , 2.9       , 4.3       , 1.3       ],\n",
       "       [5.1       , 2.5       , 3.        , 1.1       ],\n",
       "       [5.7       , 2.8       , 4.1       , 1.3       ],\n",
       "       [6.3       , 3.3       , 6.        , 2.5       ],\n",
       "       [5.8       , 2.7       , 5.1       , 1.9       ],\n",
       "       [7.1       , 3.        , 5.9       , 2.1       ],\n",
       "       [6.3       , 2.9       , 5.6       , 1.8       ],\n",
       "       [6.5       , 3.        , 5.8       , 2.2       ],\n",
       "       [7.6       , 3.        , 6.6       , 2.1       ],\n",
       "       [4.9       , 2.5       , 4.5       , 1.7       ],\n",
       "       [7.3       , 2.9       , 6.3       , 1.8       ],\n",
       "       [6.7       , 2.5       , 5.8       , 1.8       ],\n",
       "       [7.2       , 3.6       , 6.1       , 2.5       ],\n",
       "       [6.5       , 3.2       , 5.1       , 2.        ],\n",
       "       [6.4       , 2.7       , 5.3       , 1.9       ],\n",
       "       [6.8       , 3.        , 5.5       , 2.1       ],\n",
       "       [5.7       , 2.5       , 5.        , 2.        ],\n",
       "       [5.8       , 2.8       , 5.1       , 2.4       ],\n",
       "       [6.4       , 3.2       , 5.3       , 2.3       ],\n",
       "       [6.5       , 3.        , 5.5       , 1.8       ],\n",
       "       [7.7       , 3.8       , 6.7       , 2.2       ],\n",
       "       [7.7       , 2.6       , 6.9       , 2.3       ],\n",
       "       [6.        , 2.2       , 5.        , 1.5       ],\n",
       "       [6.9       , 3.2       , 5.7       , 2.3       ],\n",
       "       [5.6       , 2.8       , 4.9       , 2.        ],\n",
       "       [7.7       , 2.8       , 6.7       , 2.        ],\n",
       "       [6.3       , 2.7       , 4.9       , 1.8       ],\n",
       "       [6.7       , 3.3       , 5.7       , 2.1       ],\n",
       "       [7.2       , 3.2       , 6.        , 1.8       ],\n",
       "       [6.2       , 2.8       , 4.8       , 1.8       ],\n",
       "       [6.1       , 3.        , 4.9       , 1.8       ],\n",
       "       [6.4       , 2.8       , 5.6       , 2.1       ],\n",
       "       [7.2       , 3.        , 5.8       , 1.6       ],\n",
       "       [7.4       , 2.8       , 6.1       , 1.9       ],\n",
       "       [7.9       , 3.8       , 6.4       , 2.        ],\n",
       "       [6.4       , 2.8       , 5.6       , 2.2       ],\n",
       "       [6.3       , 2.8       , 5.1       , 1.5       ],\n",
       "       [6.1       , 2.6       , 5.6       , 1.4       ],\n",
       "       [7.7       , 3.        , 6.1       , 2.3       ],\n",
       "       [6.3       , 3.4       , 5.6       , 2.4       ],\n",
       "       [6.4       , 3.1       , 5.5       , 1.8       ],\n",
       "       [6.        , 3.        , 4.8       , 1.8       ],\n",
       "       [6.9       , 3.1       , 5.4       , 2.1       ],\n",
       "       [6.7       , 3.1       , 5.6       , 2.4       ],\n",
       "       [6.9       , 3.1       , 5.1       , 2.3       ],\n",
       "       [5.8       , 2.7       , 5.1       , 1.9       ],\n",
       "       [6.8       , 3.2       , 5.9       , 2.3       ],\n",
       "       [6.7       , 3.3       , 5.7       , 2.5       ],\n",
       "       [6.7       , 3.        , 5.2       , 2.3       ],\n",
       "       [6.3       , 2.5       , 5.        , 1.9       ],\n",
       "       [6.5       , 3.        , 5.2       , 2.        ],\n",
       "       [6.2       , 3.4       , 5.4       , 2.3       ],\n",
       "       [5.9       , 3.        , 5.1       , 1.8       ]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from numpy import vstack, array, nan\n",
    "from sklearn.preprocessing import Imputer\n",
    "\n",
    "data = vstack(\n",
    "        (array([nan,nan,nan,nan]),iris.data)\n",
    "    )\n",
    "data\n",
    "\n",
    "# 缺失值计算，返回值为计算缺失值后的数据\n",
    "# 参数missing_value为缺失值的表示形式，默认为NaN\n",
    "#参数strategy为缺失值填充方式，默认为mean（均值）\n",
    "Imputer().fit_transform(data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 数据变换\n",
    "常见的数据变换有基于多项式的、基于指数函数的、基于对数函数的。4个特征，度为2的多项式转换公式如下：\n",
    "$$(x'_1,x'_2,x'_3,x'_4,x'_5,x'_6,x'_7,x'_8,x'_9,x'_{10},x'_{11},x'_{12},x'_{13},x'_{14},x'_ {15})=(1,x_1,x_2,x_3,x_4,x^2_1,x_1*x_2,x_1*x_3,x_1*x_4,x^2_2,x_2*x_3,x_2*x_4,x^2_3,x_3*x_4,x^2_4) $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.  ,  5.1 ,  3.5 , ...,  1.96,  0.28,  0.04],\n",
       "       [ 1.  ,  4.9 ,  3.  , ...,  1.96,  0.28,  0.04],\n",
       "       [ 1.  ,  4.7 ,  3.2 , ...,  1.69,  0.26,  0.04],\n",
       "       ...,\n",
       "       [ 1.  ,  6.5 ,  3.  , ..., 27.04, 10.4 ,  4.  ],\n",
       "       [ 1.  ,  6.2 ,  3.4 , ..., 29.16, 12.42,  5.29],\n",
       "       [ 1.  ,  5.9 ,  3.  , ..., 26.01,  9.18,  3.24]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "#多项式转换\n",
    "# 参数degree为度，默认值为2\n",
    "PolynomialFeatures().fit_transform(iris.data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "基于单变元函数的数据变换可以使用一个统一的方式完成，使用preproccessing库的FunctionTransformer对数据进行对数函数转换"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/sklearn/preprocessing/_function_transformer.py:97: FutureWarning: The default validate=True will be replaced by validate=False in 0.22.\n",
      "  \"validate=False in 0.22.\", FutureWarning)\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/preprocessing/_function_transformer.py:97: FutureWarning: The default validate=True will be replaced by validate=False in 0.22.\n",
      "  \"validate=False in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[1.80828877, 1.5040774 , 0.87546874, 0.18232156],\n",
       "       [1.77495235, 1.38629436, 0.87546874, 0.18232156],\n",
       "       [1.74046617, 1.43508453, 0.83290912, 0.18232156],\n",
       "       [1.7227666 , 1.41098697, 0.91629073, 0.18232156],\n",
       "       [1.79175947, 1.5260563 , 0.87546874, 0.18232156],\n",
       "       [1.85629799, 1.58923521, 0.99325177, 0.33647224],\n",
       "       [1.7227666 , 1.48160454, 0.87546874, 0.26236426],\n",
       "       [1.79175947, 1.48160454, 0.91629073, 0.18232156],\n",
       "       [1.68639895, 1.36097655, 0.87546874, 0.18232156],\n",
       "       [1.77495235, 1.41098697, 0.91629073, 0.09531018],\n",
       "       [1.85629799, 1.54756251, 0.91629073, 0.18232156],\n",
       "       [1.75785792, 1.48160454, 0.95551145, 0.18232156],\n",
       "       [1.75785792, 1.38629436, 0.87546874, 0.09531018],\n",
       "       [1.66770682, 1.38629436, 0.74193734, 0.09531018],\n",
       "       [1.91692261, 1.60943791, 0.78845736, 0.18232156],\n",
       "       [1.90210753, 1.68639895, 0.91629073, 0.33647224],\n",
       "       [1.85629799, 1.58923521, 0.83290912, 0.33647224],\n",
       "       [1.80828877, 1.5040774 , 0.87546874, 0.26236426],\n",
       "       [1.90210753, 1.56861592, 0.99325177, 0.26236426],\n",
       "       [1.80828877, 1.56861592, 0.91629073, 0.26236426],\n",
       "       [1.85629799, 1.48160454, 0.99325177, 0.18232156],\n",
       "       [1.80828877, 1.54756251, 0.91629073, 0.33647224],\n",
       "       [1.7227666 , 1.5260563 , 0.69314718, 0.18232156],\n",
       "       [1.80828877, 1.45861502, 0.99325177, 0.40546511],\n",
       "       [1.75785792, 1.48160454, 1.06471074, 0.18232156],\n",
       "       [1.79175947, 1.38629436, 0.95551145, 0.18232156],\n",
       "       [1.79175947, 1.48160454, 0.95551145, 0.33647224],\n",
       "       [1.82454929, 1.5040774 , 0.91629073, 0.18232156],\n",
       "       [1.82454929, 1.48160454, 0.87546874, 0.18232156],\n",
       "       [1.74046617, 1.43508453, 0.95551145, 0.18232156],\n",
       "       [1.75785792, 1.41098697, 0.95551145, 0.18232156],\n",
       "       [1.85629799, 1.48160454, 0.91629073, 0.33647224],\n",
       "       [1.82454929, 1.62924054, 0.91629073, 0.09531018],\n",
       "       [1.87180218, 1.64865863, 0.87546874, 0.18232156],\n",
       "       [1.77495235, 1.41098697, 0.91629073, 0.18232156],\n",
       "       [1.79175947, 1.43508453, 0.78845736, 0.18232156],\n",
       "       [1.87180218, 1.5040774 , 0.83290912, 0.18232156],\n",
       "       [1.77495235, 1.5260563 , 0.87546874, 0.09531018],\n",
       "       [1.68639895, 1.38629436, 0.83290912, 0.18232156],\n",
       "       [1.80828877, 1.48160454, 0.91629073, 0.18232156],\n",
       "       [1.79175947, 1.5040774 , 0.83290912, 0.26236426],\n",
       "       [1.70474809, 1.19392247, 0.83290912, 0.26236426],\n",
       "       [1.68639895, 1.43508453, 0.83290912, 0.18232156],\n",
       "       [1.79175947, 1.5040774 , 0.95551145, 0.47000363],\n",
       "       [1.80828877, 1.56861592, 1.06471074, 0.33647224],\n",
       "       [1.75785792, 1.38629436, 0.87546874, 0.26236426],\n",
       "       [1.80828877, 1.56861592, 0.95551145, 0.18232156],\n",
       "       [1.7227666 , 1.43508453, 0.87546874, 0.18232156],\n",
       "       [1.84054963, 1.54756251, 0.91629073, 0.18232156],\n",
       "       [1.79175947, 1.45861502, 0.87546874, 0.18232156],\n",
       "       [2.07944154, 1.43508453, 1.74046617, 0.87546874],\n",
       "       [2.00148   , 1.43508453, 1.70474809, 0.91629073],\n",
       "       [2.06686276, 1.41098697, 1.77495235, 0.91629073],\n",
       "       [1.87180218, 1.19392247, 1.60943791, 0.83290912],\n",
       "       [2.01490302, 1.33500107, 1.7227666 , 0.91629073],\n",
       "       [1.90210753, 1.33500107, 1.70474809, 0.83290912],\n",
       "       [1.98787435, 1.45861502, 1.74046617, 0.95551145],\n",
       "       [1.77495235, 1.22377543, 1.45861502, 0.69314718],\n",
       "       [2.02814825, 1.36097655, 1.7227666 , 0.83290912],\n",
       "       [1.82454929, 1.30833282, 1.58923521, 0.87546874],\n",
       "       [1.79175947, 1.09861229, 1.5040774 , 0.69314718],\n",
       "       [1.93152141, 1.38629436, 1.64865863, 0.91629073],\n",
       "       [1.94591015, 1.16315081, 1.60943791, 0.69314718],\n",
       "       [1.96009478, 1.36097655, 1.74046617, 0.87546874],\n",
       "       [1.88706965, 1.36097655, 1.5260563 , 0.83290912],\n",
       "       [2.04122033, 1.41098697, 1.68639895, 0.87546874],\n",
       "       [1.88706965, 1.38629436, 1.70474809, 0.91629073],\n",
       "       [1.91692261, 1.30833282, 1.62924054, 0.69314718],\n",
       "       [1.97408103, 1.16315081, 1.70474809, 0.91629073],\n",
       "       [1.88706965, 1.25276297, 1.58923521, 0.74193734],\n",
       "       [1.93152141, 1.43508453, 1.75785792, 1.02961942],\n",
       "       [1.96009478, 1.33500107, 1.60943791, 0.83290912],\n",
       "       [1.98787435, 1.25276297, 1.77495235, 0.91629073],\n",
       "       [1.96009478, 1.33500107, 1.74046617, 0.78845736],\n",
       "       [2.00148   , 1.36097655, 1.66770682, 0.83290912],\n",
       "       [2.02814825, 1.38629436, 1.68639895, 0.87546874],\n",
       "       [2.05412373, 1.33500107, 1.75785792, 0.87546874],\n",
       "       [2.04122033, 1.38629436, 1.79175947, 0.99325177],\n",
       "       [1.94591015, 1.36097655, 1.70474809, 0.91629073],\n",
       "       [1.90210753, 1.28093385, 1.5040774 , 0.69314718],\n",
       "       [1.87180218, 1.22377543, 1.56861592, 0.74193734],\n",
       "       [1.87180218, 1.22377543, 1.54756251, 0.69314718],\n",
       "       [1.91692261, 1.30833282, 1.58923521, 0.78845736],\n",
       "       [1.94591015, 1.30833282, 1.80828877, 0.95551145],\n",
       "       [1.85629799, 1.38629436, 1.70474809, 0.91629073],\n",
       "       [1.94591015, 1.48160454, 1.70474809, 0.95551145],\n",
       "       [2.04122033, 1.41098697, 1.74046617, 0.91629073],\n",
       "       [1.98787435, 1.19392247, 1.68639895, 0.83290912],\n",
       "       [1.88706965, 1.38629436, 1.62924054, 0.83290912],\n",
       "       [1.87180218, 1.25276297, 1.60943791, 0.83290912],\n",
       "       [1.87180218, 1.28093385, 1.68639895, 0.78845736],\n",
       "       [1.96009478, 1.38629436, 1.7227666 , 0.87546874],\n",
       "       [1.91692261, 1.28093385, 1.60943791, 0.78845736],\n",
       "       [1.79175947, 1.19392247, 1.45861502, 0.69314718],\n",
       "       [1.88706965, 1.30833282, 1.64865863, 0.83290912],\n",
       "       [1.90210753, 1.38629436, 1.64865863, 0.78845736],\n",
       "       [1.90210753, 1.36097655, 1.64865863, 0.83290912],\n",
       "       [1.97408103, 1.36097655, 1.66770682, 0.83290912],\n",
       "       [1.80828877, 1.25276297, 1.38629436, 0.74193734],\n",
       "       [1.90210753, 1.33500107, 1.62924054, 0.83290912],\n",
       "       [1.98787435, 1.45861502, 1.94591015, 1.25276297],\n",
       "       [1.91692261, 1.30833282, 1.80828877, 1.06471074],\n",
       "       [2.09186406, 1.38629436, 1.93152141, 1.13140211],\n",
       "       [1.98787435, 1.36097655, 1.88706965, 1.02961942],\n",
       "       [2.01490302, 1.38629436, 1.91692261, 1.16315081],\n",
       "       [2.1517622 , 1.38629436, 2.02814825, 1.13140211],\n",
       "       [1.77495235, 1.25276297, 1.70474809, 0.99325177],\n",
       "       [2.11625551, 1.36097655, 1.98787435, 1.02961942],\n",
       "       [2.04122033, 1.25276297, 1.91692261, 1.02961942],\n",
       "       [2.10413415, 1.5260563 , 1.96009478, 1.25276297],\n",
       "       [2.01490302, 1.43508453, 1.80828877, 1.09861229],\n",
       "       [2.00148   , 1.30833282, 1.84054963, 1.06471074],\n",
       "       [2.05412373, 1.38629436, 1.87180218, 1.13140211],\n",
       "       [1.90210753, 1.25276297, 1.79175947, 1.09861229],\n",
       "       [1.91692261, 1.33500107, 1.80828877, 1.22377543],\n",
       "       [2.00148   , 1.43508453, 1.84054963, 1.19392247],\n",
       "       [2.01490302, 1.38629436, 1.87180218, 1.02961942],\n",
       "       [2.16332303, 1.56861592, 2.04122033, 1.16315081],\n",
       "       [2.16332303, 1.28093385, 2.06686276, 1.19392247],\n",
       "       [1.94591015, 1.16315081, 1.79175947, 0.91629073],\n",
       "       [2.06686276, 1.43508453, 1.90210753, 1.19392247],\n",
       "       [1.88706965, 1.33500107, 1.77495235, 1.09861229],\n",
       "       [2.16332303, 1.33500107, 2.04122033, 1.09861229],\n",
       "       [1.98787435, 1.30833282, 1.77495235, 1.02961942],\n",
       "       [2.04122033, 1.45861502, 1.90210753, 1.13140211],\n",
       "       [2.10413415, 1.43508453, 1.94591015, 1.02961942],\n",
       "       [1.97408103, 1.33500107, 1.75785792, 1.02961942],\n",
       "       [1.96009478, 1.38629436, 1.77495235, 1.02961942],\n",
       "       [2.00148   , 1.33500107, 1.88706965, 1.13140211],\n",
       "       [2.10413415, 1.38629436, 1.91692261, 0.95551145],\n",
       "       [2.12823171, 1.33500107, 1.96009478, 1.06471074],\n",
       "       [2.18605128, 1.56861592, 2.00148   , 1.09861229],\n",
       "       [2.00148   , 1.33500107, 1.88706965, 1.16315081],\n",
       "       [1.98787435, 1.33500107, 1.80828877, 0.91629073],\n",
       "       [1.96009478, 1.28093385, 1.88706965, 0.87546874],\n",
       "       [2.16332303, 1.38629436, 1.96009478, 1.19392247],\n",
       "       [1.98787435, 1.48160454, 1.88706965, 1.22377543],\n",
       "       [2.00148   , 1.41098697, 1.87180218, 1.02961942],\n",
       "       [1.94591015, 1.38629436, 1.75785792, 1.02961942],\n",
       "       [2.06686276, 1.41098697, 1.85629799, 1.13140211],\n",
       "       [2.04122033, 1.41098697, 1.88706965, 1.22377543],\n",
       "       [2.06686276, 1.41098697, 1.80828877, 1.19392247],\n",
       "       [1.91692261, 1.30833282, 1.80828877, 1.06471074],\n",
       "       [2.05412373, 1.43508453, 1.93152141, 1.19392247],\n",
       "       [2.04122033, 1.45861502, 1.90210753, 1.25276297],\n",
       "       [2.04122033, 1.38629436, 1.82454929, 1.19392247],\n",
       "       [1.98787435, 1.25276297, 1.79175947, 1.06471074],\n",
       "       [2.01490302, 1.38629436, 1.82454929, 1.09861229],\n",
       "       [1.97408103, 1.48160454, 1.85629799, 1.19392247],\n",
       "       [1.93152141, 1.38629436, 1.80828877, 1.02961942]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from numpy import log1p\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "\n",
    "# 自定义转换函数为对数函数的数据变换\n",
    "# 第一个参数使单变元函数\n",
    "FunctionTransformer(log1p).fit_transform(iris.data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 数据预处理\n",
    "|类|功能|说明|\n",
    "|-----|--------|------|\n",
    "|StandardScaler |\t无量纲化 \t|标准化，基于特征矩阵的列，将特征值转换至服从标准正态分布\n",
    "|MinMaxScaler \t|无量纲化 \t|区间缩放，基于最大最小值，将特征值转换到[0, 1]区间上\n",
    "|Normalizer \t|归一化 |\t基于特征矩阵的行，将样本向量转换为“单位向量”\n",
    "|Binarizer |\t二值化 |\t基于给定阈值，将定量特征按阈值划分\n",
    "|OneHotEncoder |\t哑编码 \t|将定性数据编码为定量数据\n",
    "|Imputer \t|缺失值计算 |\t计算缺失值，缺失值可填充为均值等\n",
    "|PolynomialFeatures |\t多项式数据转换 |\t多项式数据转换\n",
    "|FunctionTransformer \t|自定义单元数据转换 |\t使用单变元的函数来转换数据"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 特征选择\n",
    "通常，从两个方面来选择特征：\n",
    "- 特征是否发散：如果一个特征不发散，例如方差接近于0，也就是说样本在这个特征上基本没有差异，这个特征对于样本的区分并没有什么用。\n",
    "- 特征与目标的相关性：与目标相关性高的特征，应当优先选择。\n",
    "\n",
    "根据特征选择的形式又可以将特征选择方法分为3种：\n",
    "- Filter：过滤法，按照发散性或者相关性对各个特征进行评分，设定阈值或者待选择阈值的个数，选择特征。\n",
    "- Wrapper:包装法，根据目标函数（通常是预测效果评分），每次选择若干特征，或者排除若干特征。\n",
    "- Embedded:嵌入法，先使用某些机器学习的算法和模型进行训练，得到各个特征的权值系数，根据系数从大到小选择特征。类似于Filter方法，但是是通过训练确定特征的优劣。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filter\n",
    "#### 方差选择法\n",
    "使用方差法，先要计算各个特征的方差，然后根据阈值，选择方差大于阈值的特征。使用feature_selection库的VarianceThreshold类来选择特征"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.4],\n",
       "       [1.4],\n",
       "       [1.3],\n",
       "       [1.5],\n",
       "       [1.4],\n",
       "       [1.7],\n",
       "       [1.4],\n",
       "       [1.5],\n",
       "       [1.4],\n",
       "       [1.5],\n",
       "       [1.5],\n",
       "       [1.6],\n",
       "       [1.4],\n",
       "       [1.1],\n",
       "       [1.2],\n",
       "       [1.5],\n",
       "       [1.3],\n",
       "       [1.4],\n",
       "       [1.7],\n",
       "       [1.5],\n",
       "       [1.7],\n",
       "       [1.5],\n",
       "       [1. ],\n",
       "       [1.7],\n",
       "       [1.9],\n",
       "       [1.6],\n",
       "       [1.6],\n",
       "       [1.5],\n",
       "       [1.4],\n",
       "       [1.6],\n",
       "       [1.6],\n",
       "       [1.5],\n",
       "       [1.5],\n",
       "       [1.4],\n",
       "       [1.5],\n",
       "       [1.2],\n",
       "       [1.3],\n",
       "       [1.4],\n",
       "       [1.3],\n",
       "       [1.5],\n",
       "       [1.3],\n",
       "       [1.3],\n",
       "       [1.3],\n",
       "       [1.6],\n",
       "       [1.9],\n",
       "       [1.4],\n",
       "       [1.6],\n",
       "       [1.4],\n",
       "       [1.5],\n",
       "       [1.4],\n",
       "       [4.7],\n",
       "       [4.5],\n",
       "       [4.9],\n",
       "       [4. ],\n",
       "       [4.6],\n",
       "       [4.5],\n",
       "       [4.7],\n",
       "       [3.3],\n",
       "       [4.6],\n",
       "       [3.9],\n",
       "       [3.5],\n",
       "       [4.2],\n",
       "       [4. ],\n",
       "       [4.7],\n",
       "       [3.6],\n",
       "       [4.4],\n",
       "       [4.5],\n",
       "       [4.1],\n",
       "       [4.5],\n",
       "       [3.9],\n",
       "       [4.8],\n",
       "       [4. ],\n",
       "       [4.9],\n",
       "       [4.7],\n",
       "       [4.3],\n",
       "       [4.4],\n",
       "       [4.8],\n",
       "       [5. ],\n",
       "       [4.5],\n",
       "       [3.5],\n",
       "       [3.8],\n",
       "       [3.7],\n",
       "       [3.9],\n",
       "       [5.1],\n",
       "       [4.5],\n",
       "       [4.5],\n",
       "       [4.7],\n",
       "       [4.4],\n",
       "       [4.1],\n",
       "       [4. ],\n",
       "       [4.4],\n",
       "       [4.6],\n",
       "       [4. ],\n",
       "       [3.3],\n",
       "       [4.2],\n",
       "       [4.2],\n",
       "       [4.2],\n",
       "       [4.3],\n",
       "       [3. ],\n",
       "       [4.1],\n",
       "       [6. ],\n",
       "       [5.1],\n",
       "       [5.9],\n",
       "       [5.6],\n",
       "       [5.8],\n",
       "       [6.6],\n",
       "       [4.5],\n",
       "       [6.3],\n",
       "       [5.8],\n",
       "       [6.1],\n",
       "       [5.1],\n",
       "       [5.3],\n",
       "       [5.5],\n",
       "       [5. ],\n",
       "       [5.1],\n",
       "       [5.3],\n",
       "       [5.5],\n",
       "       [6.7],\n",
       "       [6.9],\n",
       "       [5. ],\n",
       "       [5.7],\n",
       "       [4.9],\n",
       "       [6.7],\n",
       "       [4.9],\n",
       "       [5.7],\n",
       "       [6. ],\n",
       "       [4.8],\n",
       "       [4.9],\n",
       "       [5.6],\n",
       "       [5.8],\n",
       "       [6.1],\n",
       "       [6.4],\n",
       "       [5.6],\n",
       "       [5.1],\n",
       "       [5.6],\n",
       "       [6.1],\n",
       "       [5.6],\n",
       "       [5.5],\n",
       "       [4.8],\n",
       "       [5.4],\n",
       "       [5.6],\n",
       "       [5.1],\n",
       "       [5.1],\n",
       "       [5.9],\n",
       "       [5.7],\n",
       "       [5.2],\n",
       "       [5. ],\n",
       "       [5.2],\n",
       "       [5.4],\n",
       "       [5.1]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_selection import VarianceThreshold\n",
    "\n",
    "#方差选择法，返回值为特征选择后的数据\n",
    "#参数threshold为方差的阈值\n",
    "VarianceThreshold(threshold=3).fit_transform(iris.data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 相关系数法\n",
    "使用相关系数法，先要计算各个特征对目标值得相关系数以及相关系数的P值。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectKBest\n",
    "from scipy.stats import pearsonr\n",
    "\n",
    "#选择K个最好的特征，返回选择特征后的数据\n",
    "#第一个参数为计算评估是否好的函数，该函数输入特征矩阵和目标向量，输出二元组\n",
    "#（评分、P值）的数组，数组第i项为第i个特征的评分和P值。在此定义为计算相关系数\n",
    "# 参数K为选择的特征个数\n",
    "\n",
    "SelectKBest(lambda X, Y: array(map(lambda x:pearsonr(x, Y), X.T)).T, k=2).fit_transform(iris.data, iris.target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 卡方检验\n",
    "卡方检验是检验定性自变量对定性因变量的相关性。假设自变量有N种取值，因变量有M种取值，考虑自变量等于i且因变量等于j的样本频数的观察值与期望的差距，构建统计量：$$ x^2=\\sum_{}\\frac{(A-E)^2}{E} $$\n",
    "这个统计量的含义简而言之就是自变量对因变量的相关性。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.4, 0.2],\n",
       "       [1.4, 0.2],\n",
       "       [1.3, 0.2],\n",
       "       [1.5, 0.2],\n",
       "       [1.4, 0.2],\n",
       "       [1.7, 0.4],\n",
       "       [1.4, 0.3],\n",
       "       [1.5, 0.2],\n",
       "       [1.4, 0.2],\n",
       "       [1.5, 0.1],\n",
       "       [1.5, 0.2],\n",
       "       [1.6, 0.2],\n",
       "       [1.4, 0.1],\n",
       "       [1.1, 0.1],\n",
       "       [1.2, 0.2],\n",
       "       [1.5, 0.4],\n",
       "       [1.3, 0.4],\n",
       "       [1.4, 0.3],\n",
       "       [1.7, 0.3],\n",
       "       [1.5, 0.3],\n",
       "       [1.7, 0.2],\n",
       "       [1.5, 0.4],\n",
       "       [1. , 0.2],\n",
       "       [1.7, 0.5],\n",
       "       [1.9, 0.2],\n",
       "       [1.6, 0.2],\n",
       "       [1.6, 0.4],\n",
       "       [1.5, 0.2],\n",
       "       [1.4, 0.2],\n",
       "       [1.6, 0.2],\n",
       "       [1.6, 0.2],\n",
       "       [1.5, 0.4],\n",
       "       [1.5, 0.1],\n",
       "       [1.4, 0.2],\n",
       "       [1.5, 0.2],\n",
       "       [1.2, 0.2],\n",
       "       [1.3, 0.2],\n",
       "       [1.4, 0.1],\n",
       "       [1.3, 0.2],\n",
       "       [1.5, 0.2],\n",
       "       [1.3, 0.3],\n",
       "       [1.3, 0.3],\n",
       "       [1.3, 0.2],\n",
       "       [1.6, 0.6],\n",
       "       [1.9, 0.4],\n",
       "       [1.4, 0.3],\n",
       "       [1.6, 0.2],\n",
       "       [1.4, 0.2],\n",
       "       [1.5, 0.2],\n",
       "       [1.4, 0.2],\n",
       "       [4.7, 1.4],\n",
       "       [4.5, 1.5],\n",
       "       [4.9, 1.5],\n",
       "       [4. , 1.3],\n",
       "       [4.6, 1.5],\n",
       "       [4.5, 1.3],\n",
       "       [4.7, 1.6],\n",
       "       [3.3, 1. ],\n",
       "       [4.6, 1.3],\n",
       "       [3.9, 1.4],\n",
       "       [3.5, 1. ],\n",
       "       [4.2, 1.5],\n",
       "       [4. , 1. ],\n",
       "       [4.7, 1.4],\n",
       "       [3.6, 1.3],\n",
       "       [4.4, 1.4],\n",
       "       [4.5, 1.5],\n",
       "       [4.1, 1. ],\n",
       "       [4.5, 1.5],\n",
       "       [3.9, 1.1],\n",
       "       [4.8, 1.8],\n",
       "       [4. , 1.3],\n",
       "       [4.9, 1.5],\n",
       "       [4.7, 1.2],\n",
       "       [4.3, 1.3],\n",
       "       [4.4, 1.4],\n",
       "       [4.8, 1.4],\n",
       "       [5. , 1.7],\n",
       "       [4.5, 1.5],\n",
       "       [3.5, 1. ],\n",
       "       [3.8, 1.1],\n",
       "       [3.7, 1. ],\n",
       "       [3.9, 1.2],\n",
       "       [5.1, 1.6],\n",
       "       [4.5, 1.5],\n",
       "       [4.5, 1.6],\n",
       "       [4.7, 1.5],\n",
       "       [4.4, 1.3],\n",
       "       [4.1, 1.3],\n",
       "       [4. , 1.3],\n",
       "       [4.4, 1.2],\n",
       "       [4.6, 1.4],\n",
       "       [4. , 1.2],\n",
       "       [3.3, 1. ],\n",
       "       [4.2, 1.3],\n",
       "       [4.2, 1.2],\n",
       "       [4.2, 1.3],\n",
       "       [4.3, 1.3],\n",
       "       [3. , 1.1],\n",
       "       [4.1, 1.3],\n",
       "       [6. , 2.5],\n",
       "       [5.1, 1.9],\n",
       "       [5.9, 2.1],\n",
       "       [5.6, 1.8],\n",
       "       [5.8, 2.2],\n",
       "       [6.6, 2.1],\n",
       "       [4.5, 1.7],\n",
       "       [6.3, 1.8],\n",
       "       [5.8, 1.8],\n",
       "       [6.1, 2.5],\n",
       "       [5.1, 2. ],\n",
       "       [5.3, 1.9],\n",
       "       [5.5, 2.1],\n",
       "       [5. , 2. ],\n",
       "       [5.1, 2.4],\n",
       "       [5.3, 2.3],\n",
       "       [5.5, 1.8],\n",
       "       [6.7, 2.2],\n",
       "       [6.9, 2.3],\n",
       "       [5. , 1.5],\n",
       "       [5.7, 2.3],\n",
       "       [4.9, 2. ],\n",
       "       [6.7, 2. ],\n",
       "       [4.9, 1.8],\n",
       "       [5.7, 2.1],\n",
       "       [6. , 1.8],\n",
       "       [4.8, 1.8],\n",
       "       [4.9, 1.8],\n",
       "       [5.6, 2.1],\n",
       "       [5.8, 1.6],\n",
       "       [6.1, 1.9],\n",
       "       [6.4, 2. ],\n",
       "       [5.6, 2.2],\n",
       "       [5.1, 1.5],\n",
       "       [5.6, 1.4],\n",
       "       [6.1, 2.3],\n",
       "       [5.6, 2.4],\n",
       "       [5.5, 1.8],\n",
       "       [4.8, 1.8],\n",
       "       [5.4, 2.1],\n",
       "       [5.6, 2.4],\n",
       "       [5.1, 2.3],\n",
       "       [5.1, 1.9],\n",
       "       [5.9, 2.3],\n",
       "       [5.7, 2.5],\n",
       "       [5.2, 2.3],\n",
       "       [5. , 1.9],\n",
       "       [5.2, 2. ],\n",
       "       [5.4, 2.3],\n",
       "       [5.1, 1.8]])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2\n",
    "\n",
    "#选择K个最好的特征，返回选择特征后的数据\n",
    "SelectKBest(chi2,k=2).fit_transform(iris.data,iris.target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 互信息法"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "经典互信息也是评价定性自变量对定性因变量的相关性的，互信息计算公式如下：\n",
    "$$ I(X;Y)= \\sum_{x\\in X} \\sum_{y\\in Y} p(x,y)log\\frac{p(x,y)}{p(x)p(y)}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "为了处理定量数据，最大信息系数法被提出。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectKBest\n",
    "from minepy import MINE\n",
    "\n",
    "#由于MINE的设计不是函数式的，定义mic方法将其为函数式地，返回一个二元组，二元组的第2项设置成固定的P值0.5\n",
    "def mic(x,y):\n",
    "    m = MINE()\n",
    "    m.compute_score(x,y)\n",
    "    return (m.mic(),0.5)\n",
    "\n",
    "#选择K个最好的特征，返回特征选择后的数据\n",
    "SelectKBest(lambda X,Y:array(map(lambda x:mic(x,y),X.T)).T,k=2).fit_transform(iris.data,iris.target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wrapper\n",
    "递归消除特性法使用一个及模型来进行多伦训练，每轮训练后，消除若干权值系数的特征，再基于新的特征集进行下一轮训练。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[3.5, 0.2],\n",
       "       [3. , 0.2],\n",
       "       [3.2, 0.2],\n",
       "       [3.1, 0.2],\n",
       "       [3.6, 0.2],\n",
       "       [3.9, 0.4],\n",
       "       [3.4, 0.3],\n",
       "       [3.4, 0.2],\n",
       "       [2.9, 0.2],\n",
       "       [3.1, 0.1],\n",
       "       [3.7, 0.2],\n",
       "       [3.4, 0.2],\n",
       "       [3. , 0.1],\n",
       "       [3. , 0.1],\n",
       "       [4. , 0.2],\n",
       "       [4.4, 0.4],\n",
       "       [3.9, 0.4],\n",
       "       [3.5, 0.3],\n",
       "       [3.8, 0.3],\n",
       "       [3.8, 0.3],\n",
       "       [3.4, 0.2],\n",
       "       [3.7, 0.4],\n",
       "       [3.6, 0.2],\n",
       "       [3.3, 0.5],\n",
       "       [3.4, 0.2],\n",
       "       [3. , 0.2],\n",
       "       [3.4, 0.4],\n",
       "       [3.5, 0.2],\n",
       "       [3.4, 0.2],\n",
       "       [3.2, 0.2],\n",
       "       [3.1, 0.2],\n",
       "       [3.4, 0.4],\n",
       "       [4.1, 0.1],\n",
       "       [4.2, 0.2],\n",
       "       [3.1, 0.2],\n",
       "       [3.2, 0.2],\n",
       "       [3.5, 0.2],\n",
       "       [3.6, 0.1],\n",
       "       [3. , 0.2],\n",
       "       [3.4, 0.2],\n",
       "       [3.5, 0.3],\n",
       "       [2.3, 0.3],\n",
       "       [3.2, 0.2],\n",
       "       [3.5, 0.6],\n",
       "       [3.8, 0.4],\n",
       "       [3. , 0.3],\n",
       "       [3.8, 0.2],\n",
       "       [3.2, 0.2],\n",
       "       [3.7, 0.2],\n",
       "       [3.3, 0.2],\n",
       "       [3.2, 1.4],\n",
       "       [3.2, 1.5],\n",
       "       [3.1, 1.5],\n",
       "       [2.3, 1.3],\n",
       "       [2.8, 1.5],\n",
       "       [2.8, 1.3],\n",
       "       [3.3, 1.6],\n",
       "       [2.4, 1. ],\n",
       "       [2.9, 1.3],\n",
       "       [2.7, 1.4],\n",
       "       [2. , 1. ],\n",
       "       [3. , 1.5],\n",
       "       [2.2, 1. ],\n",
       "       [2.9, 1.4],\n",
       "       [2.9, 1.3],\n",
       "       [3.1, 1.4],\n",
       "       [3. , 1.5],\n",
       "       [2.7, 1. ],\n",
       "       [2.2, 1.5],\n",
       "       [2.5, 1.1],\n",
       "       [3.2, 1.8],\n",
       "       [2.8, 1.3],\n",
       "       [2.5, 1.5],\n",
       "       [2.8, 1.2],\n",
       "       [2.9, 1.3],\n",
       "       [3. , 1.4],\n",
       "       [2.8, 1.4],\n",
       "       [3. , 1.7],\n",
       "       [2.9, 1.5],\n",
       "       [2.6, 1. ],\n",
       "       [2.4, 1.1],\n",
       "       [2.4, 1. ],\n",
       "       [2.7, 1.2],\n",
       "       [2.7, 1.6],\n",
       "       [3. , 1.5],\n",
       "       [3.4, 1.6],\n",
       "       [3.1, 1.5],\n",
       "       [2.3, 1.3],\n",
       "       [3. , 1.3],\n",
       "       [2.5, 1.3],\n",
       "       [2.6, 1.2],\n",
       "       [3. , 1.4],\n",
       "       [2.6, 1.2],\n",
       "       [2.3, 1. ],\n",
       "       [2.7, 1.3],\n",
       "       [3. , 1.2],\n",
       "       [2.9, 1.3],\n",
       "       [2.9, 1.3],\n",
       "       [2.5, 1.1],\n",
       "       [2.8, 1.3],\n",
       "       [3.3, 2.5],\n",
       "       [2.7, 1.9],\n",
       "       [3. , 2.1],\n",
       "       [2.9, 1.8],\n",
       "       [3. , 2.2],\n",
       "       [3. , 2.1],\n",
       "       [2.5, 1.7],\n",
       "       [2.9, 1.8],\n",
       "       [2.5, 1.8],\n",
       "       [3.6, 2.5],\n",
       "       [3.2, 2. ],\n",
       "       [2.7, 1.9],\n",
       "       [3. , 2.1],\n",
       "       [2.5, 2. ],\n",
       "       [2.8, 2.4],\n",
       "       [3.2, 2.3],\n",
       "       [3. , 1.8],\n",
       "       [3.8, 2.2],\n",
       "       [2.6, 2.3],\n",
       "       [2.2, 1.5],\n",
       "       [3.2, 2.3],\n",
       "       [2.8, 2. ],\n",
       "       [2.8, 2. ],\n",
       "       [2.7, 1.8],\n",
       "       [3.3, 2.1],\n",
       "       [3.2, 1.8],\n",
       "       [2.8, 1.8],\n",
       "       [3. , 1.8],\n",
       "       [2.8, 2.1],\n",
       "       [3. , 1.6],\n",
       "       [2.8, 1.9],\n",
       "       [3.8, 2. ],\n",
       "       [2.8, 2.2],\n",
       "       [2.8, 1.5],\n",
       "       [2.6, 1.4],\n",
       "       [3. , 2.3],\n",
       "       [3.4, 2.4],\n",
       "       [3.1, 1.8],\n",
       "       [3. , 1.8],\n",
       "       [3.1, 2.1],\n",
       "       [3.1, 2.4],\n",
       "       [3.1, 2.3],\n",
       "       [2.7, 1.9],\n",
       "       [3.2, 2.3],\n",
       "       [3.3, 2.5],\n",
       "       [3. , 2.3],\n",
       "       [2.5, 1.9],\n",
       "       [3. , 2. ],\n",
       "       [3.4, 2.3],\n",
       "       [3. , 1.8]])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "#递归特征消除法，返回特征选择后的数据\n",
    "#参数estimator为基模型\n",
    "#参数n_features_to_select为选择的特征个数\n",
    "RFE(estimator=LogisticRegression(),\n",
    "   n_features_to_select=2).fit_transform(iris.data,iris.target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Embedded\n",
    "### 基于惩罚项的特征选择法\n",
    "使用带惩戒的基模型，除了筛选出特征外，同时也进行了**降维**。使用feature_selection库的SelectFromModel类结合带L1惩罚项的逻辑回归模型。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[5.1, 3.5, 1.4],\n",
       "       [4.9, 3. , 1.4],\n",
       "       [4.7, 3.2, 1.3],\n",
       "       [4.6, 3.1, 1.5],\n",
       "       [5. , 3.6, 1.4],\n",
       "       [5.4, 3.9, 1.7],\n",
       "       [4.6, 3.4, 1.4],\n",
       "       [5. , 3.4, 1.5],\n",
       "       [4.4, 2.9, 1.4],\n",
       "       [4.9, 3.1, 1.5],\n",
       "       [5.4, 3.7, 1.5],\n",
       "       [4.8, 3.4, 1.6],\n",
       "       [4.8, 3. , 1.4],\n",
       "       [4.3, 3. , 1.1],\n",
       "       [5.8, 4. , 1.2],\n",
       "       [5.7, 4.4, 1.5],\n",
       "       [5.4, 3.9, 1.3],\n",
       "       [5.1, 3.5, 1.4],\n",
       "       [5.7, 3.8, 1.7],\n",
       "       [5.1, 3.8, 1.5],\n",
       "       [5.4, 3.4, 1.7],\n",
       "       [5.1, 3.7, 1.5],\n",
       "       [4.6, 3.6, 1. ],\n",
       "       [5.1, 3.3, 1.7],\n",
       "       [4.8, 3.4, 1.9],\n",
       "       [5. , 3. , 1.6],\n",
       "       [5. , 3.4, 1.6],\n",
       "       [5.2, 3.5, 1.5],\n",
       "       [5.2, 3.4, 1.4],\n",
       "       [4.7, 3.2, 1.6],\n",
       "       [4.8, 3.1, 1.6],\n",
       "       [5.4, 3.4, 1.5],\n",
       "       [5.2, 4.1, 1.5],\n",
       "       [5.5, 4.2, 1.4],\n",
       "       [4.9, 3.1, 1.5],\n",
       "       [5. , 3.2, 1.2],\n",
       "       [5.5, 3.5, 1.3],\n",
       "       [4.9, 3.6, 1.4],\n",
       "       [4.4, 3. , 1.3],\n",
       "       [5.1, 3.4, 1.5],\n",
       "       [5. , 3.5, 1.3],\n",
       "       [4.5, 2.3, 1.3],\n",
       "       [4.4, 3.2, 1.3],\n",
       "       [5. , 3.5, 1.6],\n",
       "       [5.1, 3.8, 1.9],\n",
       "       [4.8, 3. , 1.4],\n",
       "       [5.1, 3.8, 1.6],\n",
       "       [4.6, 3.2, 1.4],\n",
       "       [5.3, 3.7, 1.5],\n",
       "       [5. , 3.3, 1.4],\n",
       "       [7. , 3.2, 4.7],\n",
       "       [6.4, 3.2, 4.5],\n",
       "       [6.9, 3.1, 4.9],\n",
       "       [5.5, 2.3, 4. ],\n",
       "       [6.5, 2.8, 4.6],\n",
       "       [5.7, 2.8, 4.5],\n",
       "       [6.3, 3.3, 4.7],\n",
       "       [4.9, 2.4, 3.3],\n",
       "       [6.6, 2.9, 4.6],\n",
       "       [5.2, 2.7, 3.9],\n",
       "       [5. , 2. , 3.5],\n",
       "       [5.9, 3. , 4.2],\n",
       "       [6. , 2.2, 4. ],\n",
       "       [6.1, 2.9, 4.7],\n",
       "       [5.6, 2.9, 3.6],\n",
       "       [6.7, 3.1, 4.4],\n",
       "       [5.6, 3. , 4.5],\n",
       "       [5.8, 2.7, 4.1],\n",
       "       [6.2, 2.2, 4.5],\n",
       "       [5.6, 2.5, 3.9],\n",
       "       [5.9, 3.2, 4.8],\n",
       "       [6.1, 2.8, 4. ],\n",
       "       [6.3, 2.5, 4.9],\n",
       "       [6.1, 2.8, 4.7],\n",
       "       [6.4, 2.9, 4.3],\n",
       "       [6.6, 3. , 4.4],\n",
       "       [6.8, 2.8, 4.8],\n",
       "       [6.7, 3. , 5. ],\n",
       "       [6. , 2.9, 4.5],\n",
       "       [5.7, 2.6, 3.5],\n",
       "       [5.5, 2.4, 3.8],\n",
       "       [5.5, 2.4, 3.7],\n",
       "       [5.8, 2.7, 3.9],\n",
       "       [6. , 2.7, 5.1],\n",
       "       [5.4, 3. , 4.5],\n",
       "       [6. , 3.4, 4.5],\n",
       "       [6.7, 3.1, 4.7],\n",
       "       [6.3, 2.3, 4.4],\n",
       "       [5.6, 3. , 4.1],\n",
       "       [5.5, 2.5, 4. ],\n",
       "       [5.5, 2.6, 4.4],\n",
       "       [6.1, 3. , 4.6],\n",
       "       [5.8, 2.6, 4. ],\n",
       "       [5. , 2.3, 3.3],\n",
       "       [5.6, 2.7, 4.2],\n",
       "       [5.7, 3. , 4.2],\n",
       "       [5.7, 2.9, 4.2],\n",
       "       [6.2, 2.9, 4.3],\n",
       "       [5.1, 2.5, 3. ],\n",
       "       [5.7, 2.8, 4.1],\n",
       "       [6.3, 3.3, 6. ],\n",
       "       [5.8, 2.7, 5.1],\n",
       "       [7.1, 3. , 5.9],\n",
       "       [6.3, 2.9, 5.6],\n",
       "       [6.5, 3. , 5.8],\n",
       "       [7.6, 3. , 6.6],\n",
       "       [4.9, 2.5, 4.5],\n",
       "       [7.3, 2.9, 6.3],\n",
       "       [6.7, 2.5, 5.8],\n",
       "       [7.2, 3.6, 6.1],\n",
       "       [6.5, 3.2, 5.1],\n",
       "       [6.4, 2.7, 5.3],\n",
       "       [6.8, 3. , 5.5],\n",
       "       [5.7, 2.5, 5. ],\n",
       "       [5.8, 2.8, 5.1],\n",
       "       [6.4, 3.2, 5.3],\n",
       "       [6.5, 3. , 5.5],\n",
       "       [7.7, 3.8, 6.7],\n",
       "       [7.7, 2.6, 6.9],\n",
       "       [6. , 2.2, 5. ],\n",
       "       [6.9, 3.2, 5.7],\n",
       "       [5.6, 2.8, 4.9],\n",
       "       [7.7, 2.8, 6.7],\n",
       "       [6.3, 2.7, 4.9],\n",
       "       [6.7, 3.3, 5.7],\n",
       "       [7.2, 3.2, 6. ],\n",
       "       [6.2, 2.8, 4.8],\n",
       "       [6.1, 3. , 4.9],\n",
       "       [6.4, 2.8, 5.6],\n",
       "       [7.2, 3. , 5.8],\n",
       "       [7.4, 2.8, 6.1],\n",
       "       [7.9, 3.8, 6.4],\n",
       "       [6.4, 2.8, 5.6],\n",
       "       [6.3, 2.8, 5.1],\n",
       "       [6.1, 2.6, 5.6],\n",
       "       [7.7, 3. , 6.1],\n",
       "       [6.3, 3.4, 5.6],\n",
       "       [6.4, 3.1, 5.5],\n",
       "       [6. , 3. , 4.8],\n",
       "       [6.9, 3.1, 5.4],\n",
       "       [6.7, 3.1, 5.6],\n",
       "       [6.9, 3.1, 5.1],\n",
       "       [5.8, 2.7, 5.1],\n",
       "       [6.8, 3.2, 5.9],\n",
       "       [6.7, 3.3, 5.7],\n",
       "       [6.7, 3. , 5.2],\n",
       "       [6.3, 2.5, 5. ],\n",
       "       [6.5, 3. , 5.2],\n",
       "       [6.2, 3.4, 5.4],\n",
       "       [5.9, 3. , 5.1]])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "#带L1惩罚项的逻辑回归作为基模型的特征选择\n",
    "SelectFromModel(LogisticRegression(penalty=\"l1\",C=0.1)).fit_transform(iris.data,iris.target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "L1带惩戒项降维的原理在于保留多个对目标值具有同等相关性的特征中的一个，所以没选到的特征不代表不重要。故，可结合L2惩罚项来优化。具体为：\n",
    "> 若一个特征在L1中的权值为1，选择在L2中权值差别不大且在L1中权值为0的特征构成同类集合，将这一集合中的特征评分为L1中的权值。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectFromModel\n",
    "\n",
    "#带L1和L2惩罚项的逻辑回归作为基模型的特征选择\n",
    "#参数threshold为权值系数之差的阈值\n",
    "# SelectFromModel(LR(th))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 基于树模型的特征选择法\n",
    "树模型中GBDT也可用来作为基模型进行特征选择。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.4, 0.2],\n",
       "       [1.4, 0.2],\n",
       "       [1.3, 0.2],\n",
       "       [1.5, 0.2],\n",
       "       [1.4, 0.2],\n",
       "       [1.7, 0.4],\n",
       "       [1.4, 0.3],\n",
       "       [1.5, 0.2],\n",
       "       [1.4, 0.2],\n",
       "       [1.5, 0.1],\n",
       "       [1.5, 0.2],\n",
       "       [1.6, 0.2],\n",
       "       [1.4, 0.1],\n",
       "       [1.1, 0.1],\n",
       "       [1.2, 0.2],\n",
       "       [1.5, 0.4],\n",
       "       [1.3, 0.4],\n",
       "       [1.4, 0.3],\n",
       "       [1.7, 0.3],\n",
       "       [1.5, 0.3],\n",
       "       [1.7, 0.2],\n",
       "       [1.5, 0.4],\n",
       "       [1. , 0.2],\n",
       "       [1.7, 0.5],\n",
       "       [1.9, 0.2],\n",
       "       [1.6, 0.2],\n",
       "       [1.6, 0.4],\n",
       "       [1.5, 0.2],\n",
       "       [1.4, 0.2],\n",
       "       [1.6, 0.2],\n",
       "       [1.6, 0.2],\n",
       "       [1.5, 0.4],\n",
       "       [1.5, 0.1],\n",
       "       [1.4, 0.2],\n",
       "       [1.5, 0.2],\n",
       "       [1.2, 0.2],\n",
       "       [1.3, 0.2],\n",
       "       [1.4, 0.1],\n",
       "       [1.3, 0.2],\n",
       "       [1.5, 0.2],\n",
       "       [1.3, 0.3],\n",
       "       [1.3, 0.3],\n",
       "       [1.3, 0.2],\n",
       "       [1.6, 0.6],\n",
       "       [1.9, 0.4],\n",
       "       [1.4, 0.3],\n",
       "       [1.6, 0.2],\n",
       "       [1.4, 0.2],\n",
       "       [1.5, 0.2],\n",
       "       [1.4, 0.2],\n",
       "       [4.7, 1.4],\n",
       "       [4.5, 1.5],\n",
       "       [4.9, 1.5],\n",
       "       [4. , 1.3],\n",
       "       [4.6, 1.5],\n",
       "       [4.5, 1.3],\n",
       "       [4.7, 1.6],\n",
       "       [3.3, 1. ],\n",
       "       [4.6, 1.3],\n",
       "       [3.9, 1.4],\n",
       "       [3.5, 1. ],\n",
       "       [4.2, 1.5],\n",
       "       [4. , 1. ],\n",
       "       [4.7, 1.4],\n",
       "       [3.6, 1.3],\n",
       "       [4.4, 1.4],\n",
       "       [4.5, 1.5],\n",
       "       [4.1, 1. ],\n",
       "       [4.5, 1.5],\n",
       "       [3.9, 1.1],\n",
       "       [4.8, 1.8],\n",
       "       [4. , 1.3],\n",
       "       [4.9, 1.5],\n",
       "       [4.7, 1.2],\n",
       "       [4.3, 1.3],\n",
       "       [4.4, 1.4],\n",
       "       [4.8, 1.4],\n",
       "       [5. , 1.7],\n",
       "       [4.5, 1.5],\n",
       "       [3.5, 1. ],\n",
       "       [3.8, 1.1],\n",
       "       [3.7, 1. ],\n",
       "       [3.9, 1.2],\n",
       "       [5.1, 1.6],\n",
       "       [4.5, 1.5],\n",
       "       [4.5, 1.6],\n",
       "       [4.7, 1.5],\n",
       "       [4.4, 1.3],\n",
       "       [4.1, 1.3],\n",
       "       [4. , 1.3],\n",
       "       [4.4, 1.2],\n",
       "       [4.6, 1.4],\n",
       "       [4. , 1.2],\n",
       "       [3.3, 1. ],\n",
       "       [4.2, 1.3],\n",
       "       [4.2, 1.2],\n",
       "       [4.2, 1.3],\n",
       "       [4.3, 1.3],\n",
       "       [3. , 1.1],\n",
       "       [4.1, 1.3],\n",
       "       [6. , 2.5],\n",
       "       [5.1, 1.9],\n",
       "       [5.9, 2.1],\n",
       "       [5.6, 1.8],\n",
       "       [5.8, 2.2],\n",
       "       [6.6, 2.1],\n",
       "       [4.5, 1.7],\n",
       "       [6.3, 1.8],\n",
       "       [5.8, 1.8],\n",
       "       [6.1, 2.5],\n",
       "       [5.1, 2. ],\n",
       "       [5.3, 1.9],\n",
       "       [5.5, 2.1],\n",
       "       [5. , 2. ],\n",
       "       [5.1, 2.4],\n",
       "       [5.3, 2.3],\n",
       "       [5.5, 1.8],\n",
       "       [6.7, 2.2],\n",
       "       [6.9, 2.3],\n",
       "       [5. , 1.5],\n",
       "       [5.7, 2.3],\n",
       "       [4.9, 2. ],\n",
       "       [6.7, 2. ],\n",
       "       [4.9, 1.8],\n",
       "       [5.7, 2.1],\n",
       "       [6. , 1.8],\n",
       "       [4.8, 1.8],\n",
       "       [4.9, 1.8],\n",
       "       [5.6, 2.1],\n",
       "       [5.8, 1.6],\n",
       "       [6.1, 1.9],\n",
       "       [6.4, 2. ],\n",
       "       [5.6, 2.2],\n",
       "       [5.1, 1.5],\n",
       "       [5.6, 1.4],\n",
       "       [6.1, 2.3],\n",
       "       [5.6, 2.4],\n",
       "       [5.5, 1.8],\n",
       "       [4.8, 1.8],\n",
       "       [5.4, 2.1],\n",
       "       [5.6, 2.4],\n",
       "       [5.1, 2.3],\n",
       "       [5.1, 1.9],\n",
       "       [5.9, 2.3],\n",
       "       [5.7, 2.5],\n",
       "       [5.2, 2.3],\n",
       "       [5. , 1.9],\n",
       "       [5.2, 2. ],\n",
       "       [5.4, 2.3],\n",
       "       [5.1, 1.8]])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "SelectFromModel(GradientBoostingClassifier()).fit_transform(iris.data,iris.target\n",
    "                                                           )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 总结\n",
    "\n",
    "|类|所属方式|说明|\n",
    "|------|-------|-------|\n",
    "|VarianceThreshold |\tFilter |\t方差选择法 |\n",
    "|SelectKBest \t|Filter |\t可选关联系数、卡方校验、最大信息系数作为得分计算的方法 |\n",
    "|RFE |\tWrapper |\t递归地训练基模型，将权值系数较小的特征从特征集合中消除|\n",
    "|SelectFromModel |\tEmbedded |\t训练基模型，选择权值系数较高的特征 |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 降维\n",
    "当特征选择完成后，可以直接训练模型了，但是可能由于特征矩阵过大，导致计算量大，训练时间长的问题，因此降低特征矩阵维度也是必不可少的。常见的键位方法除了基于L1惩罚项的模型以外，还有主成分分析法（PCA）和线性判别分析（LDA），线性判别分析本身也是一个分类模型。PCA和LDA有很多相似点，其本质是要将原始的样本映射到维度更低的样本空间中，但是PCA和LDA映射目标不一样：PCA是为了让映射后的样本具有更大的发散性；而LDA是为了让映射后的样本有更好的分类性能。所以说PCA是一种无监督的降维方法，而LDA是一种由监督的降维方法。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 主成分分析法（PCA）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-2.68412563,  0.31939725, -0.02791483],\n",
       "       [-2.71414169, -0.17700123, -0.21046427],\n",
       "       [-2.88899057, -0.14494943,  0.01790026],\n",
       "       [-2.74534286, -0.31829898,  0.03155937],\n",
       "       [-2.72871654,  0.32675451,  0.09007924],\n",
       "       [-2.28085963,  0.74133045,  0.16867766],\n",
       "       [-2.82053775, -0.08946138,  0.25789216],\n",
       "       [-2.62614497,  0.16338496, -0.02187932],\n",
       "       [-2.88638273, -0.57831175,  0.02075957],\n",
       "       [-2.6727558 , -0.11377425, -0.19763272],\n",
       "       [-2.50694709,  0.6450689 , -0.07531801],\n",
       "       [-2.61275523,  0.01472994,  0.10215026],\n",
       "       [-2.78610927, -0.235112  , -0.20684443],\n",
       "       [-3.22380374, -0.51139459,  0.06129967],\n",
       "       [-2.64475039,  1.17876464, -0.15162752],\n",
       "       [-2.38603903,  1.33806233,  0.2777769 ],\n",
       "       [-2.62352788,  0.81067951,  0.13818323],\n",
       "       [-2.64829671,  0.31184914,  0.02666832],\n",
       "       [-2.19982032,  0.87283904, -0.12030552],\n",
       "       [-2.5879864 ,  0.51356031,  0.21366517],\n",
       "       [-2.31025622,  0.39134594, -0.23944404],\n",
       "       [-2.54370523,  0.43299606,  0.20845723],\n",
       "       [-3.21593942,  0.13346807,  0.29239675],\n",
       "       [-2.30273318,  0.09870885,  0.03912326],\n",
       "       [-2.35575405, -0.03728186,  0.12502108],\n",
       "       [-2.50666891, -0.14601688, -0.25342004],\n",
       "       [-2.46882007,  0.13095149,  0.09491058],\n",
       "       [-2.56231991,  0.36771886, -0.07849421],\n",
       "       [-2.63953472,  0.31203998, -0.1459089 ],\n",
       "       [-2.63198939, -0.19696122,  0.04077108],\n",
       "       [-2.58739848, -0.20431849, -0.07722299],\n",
       "       [-2.4099325 ,  0.41092426, -0.14552497],\n",
       "       [-2.64886233,  0.81336382,  0.22566915],\n",
       "       [-2.59873675,  1.09314576,  0.15781081],\n",
       "       [-2.63692688, -0.12132235, -0.14304958],\n",
       "       [-2.86624165,  0.06936447, -0.16433231],\n",
       "       [-2.62523805,  0.59937002, -0.26835038],\n",
       "       [-2.80068412,  0.26864374,  0.09369908],\n",
       "       [-2.98050204, -0.48795834,  0.07292705],\n",
       "       [-2.59000631,  0.22904384, -0.0800823 ],\n",
       "       [-2.77010243,  0.26352753,  0.07724769],\n",
       "       [-2.84936871, -0.94096057, -0.34923038],\n",
       "       [-2.99740655, -0.34192606,  0.19250921],\n",
       "       [-2.40561449,  0.18887143,  0.26386795],\n",
       "       [-2.20948924,  0.43666314,  0.29874275],\n",
       "       [-2.71445143, -0.2502082 , -0.09767814],\n",
       "       [-2.53814826,  0.50377114,  0.16670564],\n",
       "       [-2.83946217, -0.22794557,  0.08372685],\n",
       "       [-2.54308575,  0.57941002, -0.01711502],\n",
       "       [-2.70335978,  0.10770608, -0.08929401],\n",
       "       [ 1.28482569,  0.68516047, -0.40656803],\n",
       "       [ 0.93248853,  0.31833364, -0.01801419],\n",
       "       [ 1.46430232,  0.50426282, -0.33832576],\n",
       "       [ 0.18331772, -0.82795901, -0.17959139],\n",
       "       [ 1.08810326,  0.07459068, -0.3077579 ],\n",
       "       [ 0.64166908, -0.41824687,  0.04107609],\n",
       "       [ 1.09506066,  0.28346827,  0.16981024],\n",
       "       [-0.74912267, -1.00489096,  0.01230292],\n",
       "       [ 1.04413183,  0.2283619 , -0.41533608],\n",
       "       [-0.0087454 , -0.72308191,  0.28114143],\n",
       "       [-0.50784088, -1.26597119, -0.26981718],\n",
       "       [ 0.51169856, -0.10398124,  0.13054775],\n",
       "       [ 0.26497651, -0.55003646, -0.69414683],\n",
       "       [ 0.98493451, -0.12481785, -0.06211441],\n",
       "       [-0.17392537, -0.25485421,  0.09045769],\n",
       "       [ 0.92786078,  0.46717949, -0.31462098],\n",
       "       [ 0.66028376, -0.35296967,  0.32802753],\n",
       "       [ 0.23610499, -0.33361077, -0.27116184],\n",
       "       [ 0.94473373, -0.54314555, -0.49951905],\n",
       "       [ 0.04522698, -0.58383438, -0.2350021 ],\n",
       "       [ 1.11628318, -0.08461685,  0.45962099],\n",
       "       [ 0.35788842, -0.06892503, -0.22985389],\n",
       "       [ 1.29818388, -0.32778731, -0.34785435],\n",
       "       [ 0.92172892, -0.18273779, -0.23107178],\n",
       "       [ 0.71485333,  0.14905594, -0.32180094],\n",
       "       [ 0.90017437,  0.32850447, -0.31620907],\n",
       "       [ 1.33202444,  0.24444088, -0.52170278],\n",
       "       [ 1.55780216,  0.26749545, -0.16492098],\n",
       "       [ 0.81329065, -0.1633503 ,  0.0354245 ],\n",
       "       [-0.30558378, -0.36826219, -0.31849158],\n",
       "       [-0.06812649, -0.70517213, -0.24421381],\n",
       "       [-0.18962247, -0.68028676, -0.30642056],\n",
       "       [ 0.13642871, -0.31403244, -0.17724277],\n",
       "       [ 1.38002644, -0.42095429,  0.01616713],\n",
       "       [ 0.58800644, -0.48428742,  0.4444335 ],\n",
       "       [ 0.80685831,  0.19418231,  0.38896306],\n",
       "       [ 1.22069088,  0.40761959, -0.23716701],\n",
       "       [ 0.81509524, -0.37203706, -0.61472084],\n",
       "       [ 0.24595768, -0.2685244 ,  0.18836681],\n",
       "       [ 0.16641322, -0.68192672, -0.06000923],\n",
       "       [ 0.46480029, -0.67071154, -0.02430686],\n",
       "       [ 0.8908152 , -0.03446444, -0.00994693],\n",
       "       [ 0.23054802, -0.40438585, -0.22941024],\n",
       "       [-0.70453176, -1.01224823, -0.10569115],\n",
       "       [ 0.35698149, -0.50491009,  0.01661717],\n",
       "       [ 0.33193448, -0.21265468,  0.08320429],\n",
       "       [ 0.37621565, -0.29321893,  0.07799635],\n",
       "       [ 0.64257601,  0.01773819, -0.20539497],\n",
       "       [-0.90646986, -0.75609337, -0.01259965],\n",
       "       [ 0.29900084, -0.34889781,  0.01058166],\n",
       "       [ 2.53119273, -0.00984911,  0.76016543],\n",
       "       [ 1.41523588, -0.57491635,  0.29632253],\n",
       "       [ 2.61667602,  0.34390315, -0.11078788],\n",
       "       [ 1.97153105, -0.1797279 ,  0.10842466],\n",
       "       [ 2.35000592, -0.04026095,  0.28538956],\n",
       "       [ 3.39703874,  0.55083667, -0.34843756],\n",
       "       [ 0.52123224, -1.19275873,  0.5456593 ],\n",
       "       [ 2.93258707,  0.3555    , -0.42023994],\n",
       "       [ 2.32122882, -0.2438315 , -0.34830439],\n",
       "       [ 2.91675097,  0.78279195,  0.42333542],\n",
       "       [ 1.66177415,  0.24222841,  0.24244019],\n",
       "       [ 1.80340195, -0.21563762, -0.03764817],\n",
       "       [ 2.1655918 ,  0.21627559,  0.03332664],\n",
       "       [ 1.34616358, -0.77681835,  0.28190288],\n",
       "       [ 1.58592822, -0.53964071,  0.62902933],\n",
       "       [ 1.90445637,  0.11925069,  0.47963982],\n",
       "       [ 1.94968906,  0.04194326,  0.04418617],\n",
       "       [ 3.48705536,  1.17573933,  0.13389487],\n",
       "       [ 3.79564542,  0.25732297, -0.51376776],\n",
       "       [ 1.30079171, -0.76114964, -0.34499504],\n",
       "       [ 2.42781791,  0.37819601,  0.21911932],\n",
       "       [ 1.19900111, -0.60609153,  0.51185551],\n",
       "       [ 3.49992004,  0.4606741 , -0.57318224],\n",
       "       [ 1.38876613, -0.20439933, -0.06452276],\n",
       "       [ 2.2754305 ,  0.33499061,  0.28615009],\n",
       "       [ 2.61409047,  0.56090136, -0.20553452],\n",
       "       [ 1.25850816, -0.17970479,  0.0458477 ],\n",
       "       [ 1.29113206, -0.11666865,  0.23125646],\n",
       "       [ 2.12360872, -0.20972948,  0.15418002],\n",
       "       [ 2.38800302,  0.4646398 , -0.44953019],\n",
       "       [ 2.84167278,  0.37526917, -0.49889808],\n",
       "       [ 3.23067366,  1.37416509, -0.11454821],\n",
       "       [ 2.15943764, -0.21727758,  0.20876317],\n",
       "       [ 1.44416124, -0.14341341, -0.15323389],\n",
       "       [ 1.78129481, -0.49990168, -0.17287519],\n",
       "       [ 3.07649993,  0.68808568, -0.33559229],\n",
       "       [ 2.14424331,  0.1400642 ,  0.73487894],\n",
       "       [ 1.90509815,  0.04930053,  0.16218024],\n",
       "       [ 1.16932634, -0.16499026,  0.28183584],\n",
       "       [ 2.10761114,  0.37228787,  0.02729113],\n",
       "       [ 2.31415471,  0.18365128,  0.32269375],\n",
       "       [ 1.9222678 ,  0.40920347,  0.1135866 ],\n",
       "       [ 1.41523588, -0.57491635,  0.29632253],\n",
       "       [ 2.56301338,  0.2778626 ,  0.29256952],\n",
       "       [ 2.41874618,  0.3047982 ,  0.50448266],\n",
       "       [ 1.94410979,  0.1875323 ,  0.17782509],\n",
       "       [ 1.52716661, -0.37531698, -0.12189817],\n",
       "       [ 1.76434572,  0.07885885,  0.13048163],\n",
       "       [ 1.90094161,  0.11662796,  0.72325156],\n",
       "       [ 1.39018886, -0.28266094,  0.36290965]])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# 主成分分析法，返回降维后的数据\n",
    "#参数n_components为主成分数目\n",
    "PCA(n_components=2).fit_transform(iris.data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 线性判别分析法（LDA）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.14959518, 0.85040482],\n",
       "       [0.17851808, 0.82148192],\n",
       "       [0.16161672, 0.83838328],\n",
       "       [0.19346008, 0.80653992],\n",
       "       [0.14750563, 0.85249437],\n",
       "       [0.21256769, 0.78743231],\n",
       "       [0.19619975, 0.80380025],\n",
       "       [0.16693903, 0.83306097],\n",
       "       [0.19820576, 0.80179424],\n",
       "       [0.15106322, 0.84893678],\n",
       "       [0.14496013, 0.85503987],\n",
       "       [0.18351643, 0.81648357],\n",
       "       [0.14706412, 0.85293588],\n",
       "       [0.12898668, 0.87101332],\n",
       "       [0.10637852, 0.89362148],\n",
       "       [0.16501221, 0.83498779],\n",
       "       [0.17234569, 0.82765431],\n",
       "       [0.179106  , 0.820894  ],\n",
       "       [0.18345353, 0.81654647],\n",
       "       [0.17554507, 0.82445493],\n",
       "       [0.18046881, 0.81953119],\n",
       "       [0.20810522, 0.79189478],\n",
       "       [0.12192118, 0.87807882],\n",
       "       [0.28175357, 0.71824643],\n",
       "       [0.22236322, 0.77763678],\n",
       "       [0.2015211 , 0.7984789 ],\n",
       "       [0.23879251, 0.76120749],\n",
       "       [0.15772062, 0.84227938],\n",
       "       [0.15181993, 0.84818007],\n",
       "       [0.19774586, 0.80225414],\n",
       "       [0.20098006, 0.79901994],\n",
       "       [0.2168111 , 0.7831889 ],\n",
       "       [0.10810912, 0.89189088],\n",
       "       [0.11786697, 0.88213303],\n",
       "       [0.18527755, 0.81472245],\n",
       "       [0.14489505, 0.85510495],\n",
       "       [0.13279146, 0.86720854],\n",
       "       [0.12089141, 0.87910859],\n",
       "       [0.17936372, 0.82063628],\n",
       "       [0.16463463, 0.83536537],\n",
       "       [0.17086738, 0.82913262],\n",
       "       [0.25861802, 0.74138198],\n",
       "       [0.16881845, 0.83118155],\n",
       "       [0.28493275, 0.71506725],\n",
       "       [0.24795153, 0.75204847],\n",
       "       [0.21385637, 0.78614363],\n",
       "       [0.15674936, 0.84325064],\n",
       "       [0.17543074, 0.82456926],\n",
       "       [0.14699697, 0.85300303],\n",
       "       [0.16079875, 0.83920125],\n",
       "       [0.69624153, 0.30375847],\n",
       "       [0.710326  , 0.289674  ],\n",
       "       [0.73568665, 0.26431335],\n",
       "       [0.77314868, 0.22685132],\n",
       "       [0.75571532, 0.24428468],\n",
       "       [0.75063249, 0.24936751],\n",
       "       [0.72999363, 0.27000637],\n",
       "       [0.67337351, 0.32662649],\n",
       "       [0.71879917, 0.28120083],\n",
       "       [0.74038577, 0.25961423],\n",
       "       [0.74295617, 0.25704383],\n",
       "       [0.72204025, 0.27795975],\n",
       "       [0.72716103, 0.27283897],\n",
       "       [0.7543775 , 0.2456225 ],\n",
       "       [0.66483492, 0.33516508],\n",
       "       [0.69106429, 0.30893571],\n",
       "       [0.75518691, 0.24481309],\n",
       "       [0.68458411, 0.31541589],\n",
       "       [0.82420623, 0.17579377],\n",
       "       [0.70995135, 0.29004865],\n",
       "       [0.77908899, 0.22091101],\n",
       "       [0.69471572, 0.30528428],\n",
       "       [0.81674729, 0.18325271],\n",
       "       [0.74202135, 0.25797865],\n",
       "       [0.70022487, 0.29977513],\n",
       "       [0.70416384, 0.29583616],\n",
       "       [0.75054802, 0.24945198],\n",
       "       [0.77974936, 0.22025064],\n",
       "       [0.75315365, 0.24684635],\n",
       "       [0.6399747 , 0.3600253 ],\n",
       "       [0.71612489, 0.28387511],\n",
       "       [0.69167173, 0.30832827],\n",
       "       [0.69354868, 0.30645132],\n",
       "       [0.82767598, 0.17232402],\n",
       "       [0.76138121, 0.23861879],\n",
       "       [0.71433899, 0.28566101],\n",
       "       [0.72655614, 0.27344386],\n",
       "       [0.77920361, 0.22079639],\n",
       "       [0.69893379, 0.30106621],\n",
       "       [0.74920789, 0.25079211],\n",
       "       [0.75960969, 0.24039031],\n",
       "       [0.73611718, 0.26388282],\n",
       "       [0.71406476, 0.28593524],\n",
       "       [0.68199953, 0.31800047],\n",
       "       [0.74005347, 0.25994653],\n",
       "       [0.69151229, 0.30848771],\n",
       "       [0.71479808, 0.28520192],\n",
       "       [0.70677811, 0.29322189],\n",
       "       [0.6373251 , 0.3626749 ],\n",
       "       [0.71700604, 0.28299396],\n",
       "       [0.88264335, 0.11735665],\n",
       "       [0.85820765, 0.14179235],\n",
       "       [0.85901711, 0.14098289],\n",
       "       [0.84799226, 0.15200774],\n",
       "       [0.87415698, 0.12584302],\n",
       "       [0.88218932, 0.11781068],\n",
       "       [0.84829068, 0.15170932],\n",
       "       [0.86228774, 0.13771226],\n",
       "       [0.88408816, 0.11591184],\n",
       "       [0.84525986, 0.15474014],\n",
       "       [0.80106085, 0.19893915],\n",
       "       [0.85481788, 0.14518212],\n",
       "       [0.84446656, 0.15553344],\n",
       "       [0.87952292, 0.12047708],\n",
       "       [0.88395755, 0.11604245],\n",
       "       [0.84070246, 0.15929754],\n",
       "       [0.82750978, 0.17249022],\n",
       "       [0.82696422, 0.17303578],\n",
       "       [0.92354108, 0.07645892],\n",
       "       [0.86291287, 0.13708713],\n",
       "       [0.85048536, 0.14951464],\n",
       "       [0.85040736, 0.14959264],\n",
       "       [0.8934543 , 0.1065457 ],\n",
       "       [0.82446771, 0.17553229],\n",
       "       [0.83126624, 0.16873376],\n",
       "       [0.82066182, 0.17933818],\n",
       "       [0.8104396 , 0.1895604 ],\n",
       "       [0.79989423, 0.20010577],\n",
       "       [0.87619714, 0.12380286],\n",
       "       [0.8097264 , 0.1902736 ],\n",
       "       [0.86542009, 0.13457991],\n",
       "       [0.79043233, 0.20956767],\n",
       "       [0.88257861, 0.11742139],\n",
       "       [0.79900812, 0.20099188],\n",
       "       [0.84897809, 0.15102191],\n",
       "       [0.86963228, 0.13036772],\n",
       "       [0.84936675, 0.15063325],\n",
       "       [0.82062011, 0.17937989],\n",
       "       [0.79596291, 0.20403709],\n",
       "       [0.82695928, 0.17304072],\n",
       "       [0.86543255, 0.13456745],\n",
       "       [0.82577997, 0.17422003],\n",
       "       [0.85820765, 0.14179235],\n",
       "       [0.8630086 , 0.1369914 ],\n",
       "       [0.86080326, 0.13919674],\n",
       "       [0.8456904 , 0.1543096 ],\n",
       "       [0.85884302, 0.14115698],\n",
       "       [0.82627956, 0.17372044],\n",
       "       [0.83349053, 0.16650947],\n",
       "       [0.81859447, 0.18140553]])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "\n",
    "#线性判别分析法，返回降维后的数据\n",
    "#参数n_components为降维后的维数\n",
    "LatentDirichletAllocation(n_components=2).fit_transform(iris.data,iris.target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 总结\n",
    "|库|类|说明|\n",
    "|----|----|----|\n",
    "|decomposition| \tPCA \t|主成分分析法\n",
    "|lda \t|LDA \t|线性判别分析法\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
